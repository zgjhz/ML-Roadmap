WEBVTT

1
00:00:01.360 --> 00:00:05.785
В последнем видео мы рассмотрели отклонения для одномерных наборов данных.

2
00:00:05.785 --> 00:00:09.580
В этом видео мы рассмотрим отклонения для наборов данных высокой размерности.

3
00:00:09.580 --> 00:00:12.525
Интуитивное определение дисперсии, которое мы использовали

4
00:00:12.525 --> 00:00:16.090
ранее, на самом деле не работает в больших размерностях таким же образом, как

5
00:00:16.090 --> 00:00:18.885
и векторы квадрата.

6
00:00:18.885 --> 00:00:21.205
Предполагая, что у нас есть двумерный набор данных,

7
00:00:21.205 --> 00:00:24.730
теперь мы можем вычислять дисперсии в направлениях X и Y.

8
00:00:24.730 --> 00:00:29.360
Но этих дисперсий недостаточно для полного описания того, что происходит в наборе данных.

9
00:00:29.360 --> 00:00:34.255
В частности, у нас есть только вариации данных в любом направлении, независимо от

10
00:00:34.255 --> 00:00:36.200
другого направления, но нас также может

11
00:00:36.200 --> 00:00:39.470
заинтересовать взаимосвязь между переменными X и Y.

12
00:00:39.470 --> 00:00:44.105
И здесь вступает в игру концепция ковариации между этими компонентами.

13
00:00:44.105 --> 00:00:47.415
Давайте рассмотрим пример в двух измерениях.

14
00:00:47.415 --> 00:00:51.880
Для этого набора данных мы можем вычислить дисперсии в направлении Y

15
00:00:51.880 --> 00:00:54.160
и дисперсии в направлении X

16
00:00:54.160 --> 00:00:58.440
, обозначенные этими вертикальными и горизонтальными полосами.

17
00:00:58.440 --> 00:01:00.740
Но этого может быть недостаточно.

18
00:01:00.740 --> 00:01:03.330
Потому что мы можем рассмотреть другие примеры,

19
00:01:03.330 --> 00:01:05.880
где дисперсии в направлениях X и Y одинаковы,

20
00:01:05.880 --> 00:01:08.805
но набор данных выглядит совсем по-другому.

21
00:01:08.805 --> 00:01:11.470
Если мы рассмотрим этот конкретный пример,

22
00:01:11.470 --> 00:01:16.280
мы получим другую форму набора данных, но дисперсии в направлении X

23
00:01:16.280 --> 00:01:19.140
и в направлении Y абсолютно одинаковы,

24
00:01:19.140 --> 00:01:22.175
а средние значения этих наборов данных также идентичны.

25
00:01:22.175 --> 00:01:26.855
И я могу посмотреть на разные наборы, подобные этому, здесь и на этот.

26
00:01:26.855 --> 00:01:30.090
Эти четыре набора данных выглядят совершенно по-разному.

27
00:01:30.090 --> 00:01:32.720
Вы видели четыре разных примера с

28
00:01:32.720 --> 00:01:35.800
четырьмя разными свойствами или формами наборов данных,

29
00:01:35.800 --> 00:01:37.185
но различия в X,

30
00:01:37.185 --> 00:01:41.150
дисперсии в Y и средние значения идентичны.

31
00:01:41.150 --> 00:01:45.340
Если мы сосредоточимся исключительно на горизонтальном и вертикальном распределении данных,

32
00:01:45.340 --> 00:01:48.905
мы не сможем объяснить корреляцию между X и Y.

33
00:01:48.905 --> 00:01:52.615
На последнем рисунке ясно видно, что в среднем,

34
00:01:52.615 --> 00:01:56.700
если значение X точки данных увеличивается, то в среднем значение

35
00:01:56.700 --> 00:01:58.415
Y уменьшается.

36
00:01:58.415 --> 00:02:01.285
Таким образом, X и Y отрицательно коррелируют.

37
00:02:01.285 --> 00:02:04.280
Эту корреляцию можно зафиксировать, расширив понятие

38
00:02:04.280 --> 00:02:07.095
дисперсии до так называемой ковариации данных.

39
00:02:07.095 --> 00:02:11.290
Ковариация между X и Y определяется следующим образом.

40
00:02:11.290 --> 00:02:14.515
Таким образом, ковариация между X и Y

41
00:02:14.515 --> 00:02:20.000
определяется как ожидаемое значение X

42
00:02:20.000 --> 00:02:23.265
минус среднее значение в направлении X, умноженное на

43
00:02:23.265 --> 00:02:28.705
Y минус среднее значение в направлении Y.

44
00:02:28.705 --> 00:02:35.100
Mu X — ожидаемое значение в направлении x.

45
00:02:35.100 --> 00:02:41.510
А Mu Y — ожидаемое значение координат Y.

46
00:02:43.615 --> 00:02:47.320
Таким образом, для двумерных данных мы можем получить четыре интересующие нас величины.

47
00:02:47.320 --> 00:02:55.080
Мы получаем дисперсию X,

48
00:02:56.430 --> 00:03:01.550
дисперсию Y.

49
00:03:01.550 --> 00:03:07.105
А также получаем члены ковариации.

50
00:03:16.225 --> 00:03:19.640
Ковариация между X и Y и ковариация между Y и X.

51
00:03:19.640 --> 00:03:26.405
Поэтому мы суммируем эти значения в этой матрице, называемой ковариационной матрицей, состоящей из четырех записей.

52
00:03:26.405 --> 00:03:29.215
А в левом верхнем углу

53
00:03:29.215 --> 00:03:35.450
мы видим дисперсию в направлении x.

54
00:03:35.450 --> 00:03:42.185
Затем мы получаем член ковариации между X и Y.

55
00:03:42.185 --> 00:03:49.460
В правом верхнем углу — ковариация между Y и X в левом нижнем углу.

56
00:03:49.460 --> 00:03:55.265
И дисперсия Y в правом нижнем углу.

57
00:03:55.265 --> 00:03:58.305
Если ковариация между X и Y положительна,

58
00:03:58.305 --> 00:04:02.550
то в среднем значение Y увеличивается, если мы увеличиваем X.

59
00:04:02.550 --> 00:04:06.280
А если ковариация между X и Y отрицательна,

60
00:04:06.280 --> 00:04:10.500
то значение Y уменьшается, если мы увеличиваем X в среднем.

61
00:04:10.500 --> 00:04:13.150
Если ковариация между X и Y равна нулю,

62
00:04:13.150 --> 00:04:15.305
X и Y не имеют ничего общего друг с другом.

63
00:04:15.305 --> 00:04:16.720
Они не коррелированы.

64
00:04:16.720 --> 00:04:20.510
Ковариационная матрица всегда представляет собой симметричную положительно определенную матрицу

65
00:04:20.510 --> 00:04:22.640
с дисперсиями по диагонали и

66
00:04:22.640 --> 00:04:26.255
перекрестной ковариацией или ковариациями на выключенных диагоналях.

67
00:04:26.255 --> 00:04:28.990
Если теперь мы рассмотрим двумерные наборы данных.

68
00:04:28.990 --> 00:04:34.600
Допустим, у нас есть набор данных, состоящий из N векторов от X1

69
00:04:34.600 --> 00:04:40.735
до Xn, и каждый Xi представляет собой RD.

70
00:04:40.735 --> 00:04:49.180
Затем мы можем вычислить дисперсию этого набора данных как единицу над N,

71
00:04:49.180 --> 00:04:58.590
умноженную на сумму I, равную 1 до N. Xi минус Mu умножить на Xi минус Mu.

72
00:04:58.590 --> 00:05:05.710
Транспонируйте, где Mu — среднее значение набора данных. Эта матрица называется ковариационной матрицей

73
00:05:05.710 --> 00:05:13.600
данных. Эта матрица представляет собой матрицу D на D.