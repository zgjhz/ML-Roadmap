WEBVTT

1
00:00:00.000 --> 00:00:02.856
[МУЗЫКА]

2
00:00:02.856 --> 00:00:06.260
В этом видео мы рассмотрим отдельные этапы PCA.

3
00:00:06.260 --> 00:00:09.320
Но прежде чем мы это сделаем, позвольте мне сделать два комментария.

4
00:00:09.320 --> 00:00:12.692
Выводя PCA, мы исходим из предположения, что наши данные центрированы,

5
00:00:12.692 --> 00:00:14.530
то есть среднее значение равно 0.

6
00:00:14.530 --> 00:00:16.590
Это предположение не всегда верно для PCA,

7
00:00:16.590 --> 00:00:19.010
и мы бы пришли к тому же результату, но

8
00:00:19.010 --> 00:00:22.569
вычитание среднего значения из данных позволяет избежать числовых проблем.

9
00:00:24.140 --> 00:00:27.450
Предположим, что значения наших данных расположены в диапазоне от десяти до восьми.

10
00:00:27.450 --> 00:00:31.720
Затем вычисление ковариационной матрицы данных требует умножения огромных чисел,

11
00:00:31.720 --> 00:00:33.680
что приводит к числовой нестабильности.

12
00:00:34.750 --> 00:00:37.510
Еще один второй шаг, который обычно рекомендуется выполнить

13
00:00:37.510 --> 00:00:41.680
после вычитания среднего значения, состоит в том, чтобы разделить каждую размерность центрированных данных на соответствующее стандартное

14
00:00:41.680 --> 00:00:44.260
отклонение.

15
00:00:44.260 --> 00:00:47.503
Это освобождает данные от единиц измерения и гарантирует, что дисперсия

16
00:00:47.503 --> 00:00:51.420
данных во всех измерениях равна 1, но корреляции остаются неизменными.

17
00:00:52.530 --> 00:00:54.049
Давайте рассмотрим пример.

18
00:00:56.781 --> 00:01:01.763
Очевидно, что в одном измерении эти данные распределяются гораздо сильнее, чем в другом,

19
00:01:01.763 --> 00:01:04.270
и наилучшая проекция PCA очевидна.

20
00:01:04.270 --> 00:01:06.810
Однако с этим набором данных есть проблема.

21
00:01:06.810 --> 00:01:10.290
Оба измерения набора данных — расстояния, но

22
00:01:10.290 --> 00:01:14.220
одно измеряется в сантиметрах, а другое — в метрах.

23
00:01:14.220 --> 00:01:18.770
Значение, измеряемое в сантиметрах, естественно, значительно отличается от другого.

24
00:01:18.770 --> 00:01:22.343
Когда мы делим каждый размер набора данных на соответствующее стандартное

25
00:01:22.343 --> 00:01:24.157
отклонение, мы избавляемся от единиц измерения и

26
00:01:24.157 --> 00:01:26.666
убеждаемся в том, что дисперсия в каждом измерении равна 1.

27
00:01:30.190 --> 00:01:34.137
Рассмотрев основное подпространство этого нормализованного набора данных, мы

28
00:01:34.137 --> 00:01:39.190
увидим, что между этими двумя измерениями на самом деле существует довольно сильная корреляция.

29
00:01:39.190 --> 00:01:40.830
А главная ось изменилась.

30
00:01:42.040 --> 00:01:46.501
Но теперь давайте шаг за шагом рассмотрим PCA и приведем работающий пример.

31
00:01:48.512 --> 00:01:50.676
Нам предоставлен двухмерный набор данных, и

32
00:01:50.676 --> 00:01:54.990
мы хотим использовать PCA для проецирования его в одномерное подпространство.

33
00:01:54.990 --> 00:01:57.140
Первое, что мы делаем, — это вычитаем среднее значение.

34
00:01:58.610 --> 00:01:59.820
Теперь данные центрированы.

35
00:02:00.950 --> 00:02:02.740
Затем мы делим на стандартное отклонение.

36
00:02:03.960 --> 00:02:05.650
Теперь данные не содержат единиц измерения и

37
00:02:05.650 --> 00:02:10.170
имеют дисперсию по одной по каждой оси, что обозначено этими двумя стрелками.

38
00:02:10.170 --> 00:02:12.510
Но имейте в виду, что корреляции остались неизменными.

39
00:02:17.528 --> 00:02:19.190
В-третьих, мы вычисляем ковариационную матрицу данных, ее собственные значения и соответствующие собственные векторы.

40
00:02:24.741 --> 00:02:25.716
Собственные векторы масштабируются по величине соответствующего собственного значения на этом рисунке.

41
00:02:25.716 --> 00:02:30.430
Чем длиннее вектор, занимающий основное подпространство, назовем его u,

42
00:02:30.430 --> 00:02:31.612
и на последнем этапе

43
00:02:31.612 --> 00:02:35.660
мы можем спроецировать любую точку данных x звездочку на главное подпространство.

44
00:02:35.660 --> 00:02:39.563
Чтобы сделать это правильно, нам нужно нормализовать значение x star, используя среднее значение и стандартное

45
00:02:39.563 --> 00:02:42.715
отклонение набора данных, который мы использовали для вычисления матрицы ковариаций данных.

46
00:02:45.232 --> 00:02:48.717
Таким образом, мы получим новую звезду x, а

47
00:02:48.717 --> 00:02:53.681
новая звезда x будет представлять собой старую звезду x минус среднее значение

48
00:02:53.681 --> 00:02:58.265
набора данных, деленное на стандартное отклонение.

49
00:02:58.265 --> 00:03:06.370
И мы делаем это для каждого измерения в x-звезде.

50
00:03:07.640 --> 00:03:13.010
Теперь мы можем получить проекцию звезды x в виде тильды x звезд

51
00:03:15.160 --> 00:03:19.930
или проекцию звезды x на главное подпространство u в

52
00:03:19.930 --> 00:03:24.401
виде B, умноженной на B, умноженную на x звезды.

53
00:03:29.250 --> 00:03:31.600
Где B — матрица, содержащая собственные векторы, принадлежащие наибольшим собственным значениям в виде столбцов.

54
00:03:31.600 --> 00:03:36.550
А B, переложенное на x звездочек, — это координаты

55
00:03:36.550 --> 00:03:40.630
проекции по отношению к основанию главного подпространства.

56
00:03:40.630 --> 00:03:43.420
В этом видео мы рассмотрели этапы PCA.

57
00:03:43.420 --> 00:03:45.260
Сначала мы вычитаем среднее значение из данных и

58
00:03:45.260 --> 00:03:48.070
отправляем его в нулевое значение, чтобы избежать числовых проблем.

59
00:03:48.070 --> 00:03:52.440
Во-вторых, мы делим на стандартное отклонение, чтобы данные не содержали единиц измерения.

60
00:03:52.440 --> 00:03:56.840
В-третьих, мы вычисляем собственные значения и собственные векторы матрицы ковариаций данных.

61
00:03:56.840 --> 00:04:00.518
И наконец, мы можем спроецировать любую точку данных на главное подпространство,

62
00:04:00.518 --> 00:04:04.515
охватываемое собственными векторами, принадлежащими наибольшим собственным значениям.

63
00:04:04.515 --> 00:04:07.689
[МУЗЫКА]