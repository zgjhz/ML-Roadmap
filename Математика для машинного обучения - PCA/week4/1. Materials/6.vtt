WEBVTT

1
00:00:00.000 --> 00:00:03.620
В последнем видео

2
00:00:03.620 --> 00:00:06.830
мы определили координаты оптимальной проекции относительно

3
00:00:06.830 --> 00:00:10.530
ортонормального базиса, охватывающего наше основное подпространство.

4
00:00:10.530 --> 00:00:13.750
Прежде чем мы продолжим и определим оптимальные базисные векторы,

5
00:00:13.750 --> 00:00:16.425
давайте сначала перефразируем нашу функцию потерь.

6
00:00:16.425 --> 00:00:19.160
Я скопировал результаты, которые у нас есть до сих пор.

7
00:00:19.160 --> 00:00:23.845
Таким образом, описание нашей проектируемой точки данных, нашей функции потери,

8
00:00:23.845 --> 00:00:26.830
частичной производной нашей функции потери относительно

9
00:00:26.830 --> 00:00:32.240
нашей проектируемой точки данных и оптимальных координат, которые мы нашли в видео потери.

10
00:00:32.240 --> 00:00:35.375
Прежде чем мы продолжим и определим оптимальную основу векторов,

11
00:00:35.375 --> 00:00:37.430
давайте перефразируем нашу функцию потерь.

12
00:00:37.430 --> 00:00:41.500
Это значительно упростит поиск наших базисных векторов.

13
00:00:41.500 --> 00:00:45.860
Для этого давайте подробнее рассмотрим вектор разности между

14
00:00:45.860 --> 00:00:51.325
нашей исходной точкой данных и нашей проектируемой точкой данных. Так что ты можешь писать.

15
00:00:51.325 --> 00:00:56.335
Таким образом, Xn тильда задается уравнением A,

16
00:00:56.335 --> 00:01:04.425
которое является суммой от j = 1 до M beta Jn раз bj.

17
00:01:04.425 --> 00:01:13.245
Если мы теперь используем результаты для наших Optimal beta jn параметров отсюда, мы получаем,

18
00:01:13.245 --> 00:01:21.695
это j = 1 до M xn транспонирование

19
00:01:21.695 --> 00:01:31.130
раз bj раз bj где мы использовали D. Теперь

20
00:01:31.130 --> 00:01:34.055
мы переписываем это следующим образом.

21
00:01:34.055 --> 00:01:39.200
Это просто скалярный или точечный продукт в этом конкретном случае,

22
00:01:39.200 --> 00:01:42.060
точечные продукты симметричны, поэтому мы можем поменять порядок,

23
00:01:42.060 --> 00:01:48.000
и мы также можем переместить скаляр здесь.

24
00:01:48.000 --> 00:01:58.100
Итак, что мы в конечном итоге с bj раз bj транспонирование раз Xn,

25
00:01:58.100 --> 00:02:03.580
и это мы можем написать обычно как j = 1

26
00:02:03.580 --> 00:02:09.700
до M раз bj раз bj транспонирование Xn,

27
00:02:09.700 --> 00:02:14.240
где мы перемещаем Xn из суммы.

28
00:02:14.240 --> 00:02:17.065
И если мы посмотрим на это,

29
00:02:17.065 --> 00:02:21.310
то это проекционная матрица.

30
00:02:23.980 --> 00:02:29.810
Таким образом, это означает, что Xn тильда является

31
00:02:29.810 --> 00:02:36.200
ортогональной проекцией Xn на подпространство, охватываемое векторами базиса M,

32
00:02:36.200 --> 00:02:40.230
bj где j = 1 к M. Аналогичным образом,

33
00:02:40.230 --> 00:02:47.355
мы можем написать Xn как сумма j = 1 к

34
00:02:47.355 --> 00:02:56.660
M из bj раз bj транспонирование раз Xn,

35
00:02:56.660 --> 00:03:04.690
плюс термин, который работает от M +1 до D,

36
00:03:04.690 --> 00:03:11.055
bj раз bj транспонирование раз Xn.

37
00:03:11.055 --> 00:03:16.205
Итак, мы пишем Xn как

38
00:03:16.205 --> 00:03:22.835
проекцию на основное подпространство плюс проекцию на ортогональное дополнение.

39
00:03:22.835 --> 00:03:28.350
И этот термин здесь не хватает.

40
00:03:28.350 --> 00:03:31.475
Вот почему Xn tilde является приближением к Xn.

41
00:03:31.475 --> 00:03:36.865
Итак, если мы теперь посмотрим на вектор разницы между Xn тильдой и Xn,

42
00:03:36.865 --> 00:03:44.125
то, что остается именно этот термин.

43
00:03:44.125 --> 00:03:52.985
Таким образом, Xn минус Xn тильда является

44
00:03:52.985 --> 00:03:58.210
суммой J = M + 1 до D от

45
00:03:58.210 --> 00:04:05.510
bj раз bj транспонирование раз Xn.

46
00:04:05.510 --> 00:04:08.780
Итак, теперь мы можем посмотреть на векторы смещения

47
00:04:08.780 --> 00:04:11.060
разницы между Xn и его проекцией,

48
00:04:11.060 --> 00:04:13.830
и мы видим, что

49
00:04:13.830 --> 00:04:18.610
вектор смещения лежит исключительно в подпространстве, которое мы игнорируем.

50
00:04:18.610 --> 00:04:22.415
Это означает ортогональное дополнение к основному подпространству.

51
00:04:22.415 --> 00:04:25.110
Давайте рассмотрим пример в двух измерениях.

52
00:04:25.110 --> 00:04:29.420
У нас есть набор данных и два измерения, представленные этими точками, и теперь мы

53
00:04:29.420 --> 00:04:34.125
заинтересованы в проецировании их на подпространство U1.

54
00:04:34.125 --> 00:04:36.290
Ну, мы делаем это, а затем посмотрим

55
00:04:36.290 --> 00:04:40.540
на вектор разницы между исходными данными и проектируемыми данными,

56
00:04:40.540 --> 00:04:42.530
мы получаем эти вертикальные линии.

57
00:04:42.530 --> 00:04:44.530
Это означает, что у них нет компонента x,

58
00:04:44.530 --> 00:04:46.045
нет изменения в x.

59
00:04:46.045 --> 00:04:50.740
Это означает, что у них есть только компонент, который живет в подпространстве U2, который

60
00:04:50.740 --> 00:04:55.755
является ортогональным дополнением к U1, который является подпространством, на которое мы проецировали.

61
00:04:55.755 --> 00:04:57.440
Итак, с этой иллюстрацией,

62
00:04:57.440 --> 00:04:59.620
давайте быстро переписать это немного по-другому.

63
00:04:59.620 --> 00:05:08.035
Собираясь написать это как сумма J = M +1 к D из

64
00:05:08.035 --> 00:05:15.960
bj транспонировать Xn раз bj, и мы собираемся называть

65
00:05:15.960 --> 00:05:19.810
это сейчас уравнение E. Мы посмотрели на

66
00:05:19.810 --> 00:05:22.170
вектор смещения между Xn и это

67
00:05:22.170 --> 00:05:25.800
ортогональная проекция на основное подпространство, Xn тильда.

68
00:05:25.800 --> 00:05:30.460
И теперь мы используем это, чтобы переформулировать нашу функцию потерь.

69
00:05:30.460 --> 00:05:32.850
Итак, из уравнения B,

70
00:05:32.850 --> 00:05:39.090
мы получаем, что наша функция потери 1 над N

71
00:05:39.090 --> 00:05:46.275
умножается на сумму n = 1 к N от Xn минус Xn тильды в квадрате.

72
00:05:46.275 --> 00:05:50.720
Итак, это средняя ошибка реконструкции квадрата, и теперь мы

73
00:05:50.720 --> 00:05:55.640
будем использовать уравнение Е для вектора смещения здесь.

74
00:05:55.640 --> 00:06:03.710
Таким образом, мы перепишем это сейчас, используя уравнение E как 1 над N умноженное на сумму N

75
00:06:03.710 --> 00:06:07.150
= 1 к капиталу N. И теперь мы будем

76
00:06:07.150 --> 00:06:11.610
использовать внутри этой квадратной нормы это выражение здесь.

77
00:06:11.610 --> 00:06:16.580
Таким образом, мы получаем сумму j = M + 1 до

78
00:06:16.580 --> 00:06:26.480
D из bj транспонирования раз Xn раз bj в квадрате.

79
00:06:26.480 --> 00:06:32.810
И теперь мы будем использовать тот факт, что bjs образуют

80
00:06:32.810 --> 00:06:38.990
ортонормальную основу, и это значительно упростит это выражение,

81
00:06:38.990 --> 00:06:48.225
и мы получим 1 более N раз сумму n = 1 в капитал N раз

82
00:06:48.225 --> 00:06:58.550
сумму J = M + 1 в D из bj транспонирования раз Xn в квадрате.

83
00:06:58.550 --> 00:07:01.500
И теперь мы собираемся умножить это

84
00:07:01.500 --> 00:07:07.370
явно, и мы получаем 1 над N раз сумму над

85
00:07:07.370 --> 00:07:11.920
n раз сумму над j раз

86
00:07:11.920 --> 00:07:19.815
bj транспонировать раз Xn раз Xn транспонировать раз bj.

87
00:07:19.815 --> 00:07:31.490
Итак, эта часть теперь идентична этой части.

88
00:07:31.490 --> 00:07:36.200
А теперь я собираюсь перераспределить суммы.

89
00:07:36.200 --> 00:07:40.625
Так что я собираюсь переместить сумму над j снаружи.

90
00:07:40.625 --> 00:07:43.390
Таким образом, у меня будет сумма над

91
00:07:43.390 --> 00:07:52.110
J = M + 1 до D раз транспонирование bj.

92
00:07:52.110 --> 00:07:54.490
Таким образом, это не зависит от

93
00:07:54.490 --> 00:07:58.845
n, раз 1 над

94
00:07:58.845 --> 00:08:05.430
N сумма n = 1 к N Xn раз транспонирование,

95
00:08:05.430 --> 00:08:09.915
и здесь bj отсутствует время bj.

96
00:08:09.915 --> 00:08:14.200
Так что я собираюсь поставить его в скобку сейчас таким образом.

97
00:08:14.200 --> 00:08:18.390
И то, что мы видим сейчас, это то, что если мы будем внимательно смотреть,

98
00:08:18.390 --> 00:08:28.645
мы можем идентифицировать это выражение как матрица ковариации данных S,

99
00:08:28.645 --> 00:08:31.180
потому что мы предположили, что мы центрировали данные.

100
00:08:31.180 --> 00:08:34.625
Таким образом, среднее значение данных равно нулю.

101
00:08:34.625 --> 00:08:39.795
Это означает, что теперь мы можем переписать нашу функцию потерь, используя матрицу ковариации данных,

102
00:08:39.795 --> 00:08:49.955
и мы получаем, что наша потеря является суммой над j = M + 1 до D bj

103
00:08:49.955 --> 00:08:55.960
транспонирования раз S раз bj, и мы

104
00:08:55.960 --> 00:08:58.920
также можем использовать немного другую интерпретацию,

105
00:08:58.920 --> 00:09:02.775
перестраивая несколько терминов и используя оператор трассировки.

106
00:09:02.775 --> 00:09:13.530
Итак, теперь мы можем также написать это как след суммы j = M + 1 до D bj

107
00:09:13.530 --> 00:09:17.015
раз bj

108
00:09:17.015 --> 00:09:24.090
транспонировать раз S, и

109
00:09:24.090 --> 00:09:33.090
теперь мы можем также интерпретировать эту матрицу как матрицу проекции.

110
00:09:35.580 --> 00:09:39.850
Эта проекционная матрица принимает

111
00:09:39.850 --> 00:09:42.150
нашу матрицу ковариации данных и

112
00:09:42.150 --> 00:09:44.935
проецирует ее на ортогональный комплимент основного подпространства.

113
00:09:44.935 --> 00:09:48.240
Это означает, что мы можем переформулировать функцию потери как

114
00:09:48.240 --> 00:09:52.105
дисперсию данных, проецируемых в подпространство, которое мы игнорируем.

115
00:09:52.105 --> 00:09:56.960
Таким образом, минимизация этих потерь эквивалентна

116
00:09:56.960 --> 00:09:59.480
минимизации дисперсии данных, лежащих

117
00:09:59.480 --> 00:10:02.540
в подпространстве, ортогонально основному подпространству.

118
00:10:02.540 --> 00:10:05.395
Другими словами, мы заинтересованы в сохранении

119
00:10:05.395 --> 00:10:09.550
как можно большего дисперсии после проекции.

120
00:10:09.550 --> 00:10:13.965
Переформулирование среднеквадратической ошибки реконструкции с точки зрения

121
00:10:13.965 --> 00:10:16.665
ковариации данных дает нам простой

122
00:10:16.665 --> 00:10:19.655
способ найти базисный вектор основного подпространства,

123
00:10:19.655 --> 00:10:21.930
что мы сделаем в следующем видео.