WEBVTT

1
00:00:01.050 --> 00:00:04.970
В этом курсе будет представлен

2
00:00:04.970 --> 00:00:09.510
алгоритм линейного уменьшения размерности (PCA) с анализом главных компонентов.

3
00:00:09.510 --> 00:00:11.780
PCA существует уже около ста лет

4
00:00:11.780 --> 00:00:14.060
и до сих пор остается одним из наиболее часто используемых методов

5
00:00:14.060 --> 00:00:16.490
сжатия и визуализации данных.

6
00:00:16.490 --> 00:00:19.455
Данные высокой размерности, например изображения,

7
00:00:19.455 --> 00:00:23.310
часто обладают тем свойством, что они находятся в низкоразмерном подпространстве

8
00:00:23.310 --> 00:00:26.800
и что многие измерения сильно коррелируют друг с другом.

9
00:00:26.800 --> 00:00:30.270
Вот иллюстрация в двух измерениях.

10
00:00:30.270 --> 00:00:35.680
Несмотря на то, что данные не совсем расположены на прямой линии,

11
00:00:35.680 --> 00:00:38.560
данные не сильно различаются в одном измерении

12
00:00:38.560 --> 00:00:44.645
, поэтому мы можем выразить их так, как если бы они находились на прямой, практически без потерь.

13
00:00:44.645 --> 00:00:48.170
Основная идея PCA

14
00:00:48.170 --> 00:00:50.450
заключается в использовании ортогональных проекций для поиска

15
00:00:50.450 --> 00:00:55.300
низкоразмерных представлений данных, сохраняющих как можно больше информации.

16
00:00:55.300 --> 00:00:57.470
Подобно тому примеру, который мы только что рассмотрели.

17
00:00:57.470 --> 00:00:58.805
В следующих видеороликах

18
00:00:58.805 --> 00:01:01.880
мы рассмотрим PCA как алгоритм, минимизирующий

19
00:01:01.880 --> 00:01:08.190
средние ошибки реконструкции с помощью ортогональных проекций.