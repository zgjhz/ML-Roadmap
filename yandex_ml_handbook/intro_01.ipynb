{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zbLLaSGH6Z"
      },
      "source": [
        "## Лабораторная работа \"Введение в ML\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3v975uGH6h"
      },
      "source": [
        "В этой лабораторной вы:\n",
        "\n",
        "- познакомитесь с базовыми библиотеками для работы с табличными данными — `numpy` и `pandas`\n",
        "- поближе посмотрите на простейшие задачи машинного обучения: классификацию и регрессию\n",
        "- попробуете несколько метрик и поймёте, почему выбор метрики это важно\n",
        "- обучите несколько простых моделей\n",
        "- увидите связь между сложностью модели и переобучением\n",
        "- убедитесь, что без данных всё тлен"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3nBqBSGH6j"
      },
      "source": [
        "Загрузка самых базовых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "Z8Iht5qhGH6l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8Eq0sTGH6n"
      },
      "source": [
        "### [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
        "\n",
        "С 1995 numeric, с 2006 NumPy — «Numerical Python extensions» или просто «NumPy»\n",
        "\n",
        "Возможности библиотеки NumPy:\n",
        "* работать с многомерными массивами (таблицами)\n",
        "* быстро вычислять математические функций на многомерных массивах\n",
        "\n",
        "Ядро пакета NumPy — объект [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)\n",
        "\n",
        "**Важные отличия** между NumPy arrays и Python sequences:\n",
        "* NumPy array имеет фиксированную длину, которая определяется в момент его создания (в отличие от Python lists, которые могут расти динамически)\n",
        "* Элементы в NumPy array должны быть одного типа\n",
        "* Можно выполнять операции непосредственно над NumPy arrays\n",
        "\n",
        "**Скорость** NumPy достигается с помощью:\n",
        "* реализации на C\n",
        "* векторизации и броадкастинга (broadcasting). Например, произведение массивов совместимых форм.\n",
        "\n",
        "Теперь давайте разберёмся подробнее и сделаем что-нибудь приятное и полезное в `numpy`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3UKcU6GH6o"
      },
      "source": [
        "### Индексация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqBzoEfvGH6p"
      },
      "source": [
        "В NumPy работает привычная индексация Python, ура! Включая использование отрицательных индексов и срезов (slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anq_nSYTGH6q"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "<b>Замечание 1:</b> Индексы и срезы в многомерных массивах не нужно разделять квадратными скобками,\n",
        "т.е. вместо <b>matrix[i][j]</b> нужно использовать <b>matrix[i, j]</b>. Первое тоже работает, но сначала выдаёт строку i, потом элемент j в ней.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoHXSVIrGH6q"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "<b>Замечание 2:</b> Срезы в NumPy создают view, а не копии, как в случае срезов встроенных последовательностей Python (string, tuple and list).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "YJKxBB4dGH6s",
        "outputId": "61139b1d-46db-4f7f-d5bb-96b7c3f96284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones_matrix = np.ones((5, 5))\n",
        "ones_submatrix_view = ones_matrix[::2,::2] # creates a view, not copy\n",
        "ones_matrix[::2,::2] = np.zeros((3, 3))\n",
        "ones_submatrix_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpEF1rp2GH6v"
      },
      "source": [
        "### Ссылка на Яндекс.Контест\n",
        "\n",
        "Решения и ответы в задачах, расположенных ниже, загружайте в контест на автоматическую проверку:\n",
        "https://new.contest.yandex.ru/60376/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpuxPhJGH6v"
      },
      "source": [
        "**1.** Реализуйте функцию, принимающую на вход два одномерных массива `first_array` и `second_array` и возвращающую матрицу, в которой первый массив соответствует первому столбцу матрицы, второй — второму.\n",
        "\n",
        "Вероятно первое, что приходит вам на ум, это конкатенация и транспонирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "hmQk1N6rGH6w"
      },
      "outputs": [],
      "source": [
        "def construct_matrix(first_array, second_array):\n",
        "    \"\"\"\n",
        "    Construct matrix from pair of arrays\n",
        "    :param first_array: first array\n",
        "    :param second_array: second array\n",
        "    :return: constructed matrix\n",
        "    \"\"\"\n",
        "    return np.vstack([first_array, second_array]).T # <- your first right code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "TeFqyCz4GH6x",
        "outputId": "ecd0b7d3-7acf-40f2-878e-057d17136e8c",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 3],\n",
              "       [2, 4]])"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "construct_matrix(np.array([1,2]),np.array([3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-lmcA2GH6y"
      },
      "source": [
        "(в скобках заметим, что конкатенировать можно vertically, horizontally, depth wise методами vstack, hstack, dstack по трём осям (0, 1 и 2, соотвественно), либо в общем случае `np.concatenate` — поиграйтесь ниже с прекрасным примером четырёхмерной точки, чтобы точно всё для себя понять)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "xguxLJ0VGH6y",
        "outputId": "2f32df14-6f5d-4800-96b5-bb8fba9c9ec0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[0]]]])"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = np.arange(1).reshape([1, 1, 1, 1])\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "z1JFw75eGH6y",
        "outputId": "16e3c894-2e0e-4a5a-edd4-7a974cfa43e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vstack:  (2, 1, 1, 1)\n",
            "hstack:  (1, 2, 1, 1)\n",
            "dstack:  (1, 1, 2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"vstack: \", np.vstack((p, p)).shape)\n",
        "print(\"hstack: \", np.hstack((p, p)).shape)\n",
        "print(\"dstack: \", np.dstack((p, p)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "cvbthbDDGH6z",
        "outputId": "d89430e5-8c64-4b5f-f2b3-4343f4c659ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 1, 2)"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.concatenate((p, p), axis=3).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5GkuWwaGH60"
      },
      "source": [
        "Но, поскольку операция транспонирования [делает массив non-contiguous](https://numpy.org/doc/stable/user/basics.copies.html#other-operations), мы в этой задаче **запретим** ей пользоваться и порекомедуем воспользоваться, например, методом [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ce_o75GH61"
      },
      "source": [
        "**2.** Реализуйте функцию, принимающую на вход массив целых неотрицательных чисел `nums` и возвращающую самый частый элемент массива."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "XZysMovaGH61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def most_frequent(nums):\n",
        "    \"\"\"\n",
        "    Find the most frequent value in an array\n",
        "    :param nums: array of ints\n",
        "    :return: the most frequent value\n",
        "    \"\"\"\n",
        "    return np.argmax(np.bincount(nums))  # <- your second right code here\n",
        "\n",
        "most_frequent(np.array([2, 2, 0, 0, 0, 0, 4, 5, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kjITZMGH62"
      },
      "source": [
        "### Переходим к работе с данными\n",
        "\n",
        "Прежде всего, загрузим данные и сделаем из них красивые pandas-таблички. Они взяты из параллели RecSys соревнования https://yandex.ru/cup/ml/. Но мы будем иметь дело не со всеми данными, а только с их частью. Данные у нас будут про заведения общественного питания (больше бюрократический терминологии!)\n",
        "\n",
        "Файлы с данными можно найти [здесь](https://disk.yandex.ru/d/YWvCNRQMb7QSQA).\n",
        "\n",
        "Задачей будет **предсказание среднего чека** (average_bill) по некоторым другим свойствам заведения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "yJPF3OclGH62"
      },
      "outputs": [],
      "source": [
        "base = 'data_01/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "uzDIu6uXGH62"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(base + 'organisations.csv')\n",
        "features = pd.read_csv(base + 'features.csv')\n",
        "rubrics = pd.read_csv(base + 'rubrics.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AwDM7bGH63"
      },
      "source": [
        "В основном мы будем работать с табличкой `data`; остальное вам может пригодиться, если вы захотите знать, какое содержание стоит за кодами признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hrvEN_3GH63"
      },
      "source": [
        "## Изучение данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI9YQMuCGH63"
      },
      "source": [
        "Посмотрите на данные. В этом вам поможет метод ``head`` pandas-таблички."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "VA_0DG29GH64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_id</th>\n",
              "      <th>city</th>\n",
              "      <th>average_bill</th>\n",
              "      <th>rating</th>\n",
              "      <th>rubrics_id</th>\n",
              "      <th>features_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15903868628669802651</td>\n",
              "      <td>msk</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>4.270968</td>\n",
              "      <td>30776 30774</td>\n",
              "      <td>3501685156 3501779478 20422 3502045016 3502045...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16076540698036998306</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.375000</td>\n",
              "      <td>30771</td>\n",
              "      <td>1509 1082283206 273469383 10462 11617 35017794...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8129364761615040323</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>31495</td>\n",
              "      <td>10462 11177 11617 11629 1416 1018 11704 11867 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15262729117594253452</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.538813</td>\n",
              "      <td>30776 30770</td>\n",
              "      <td>3501618484 2020795524 11629 11617 1018 11704 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13418544315327784420</td>\n",
              "      <td>msk</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.409091</td>\n",
              "      <td>31495</td>\n",
              "      <td>11617 10462 11177 1416 11867 3501744275 20282 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 org_id city  average_bill    rating   rubrics_id  \\\n",
              "0  15903868628669802651  msk        1500.0  4.270968  30776 30774   \n",
              "1  16076540698036998306  msk         500.0  4.375000        30771   \n",
              "2   8129364761615040323  msk         500.0  4.000000        31495   \n",
              "3  15262729117594253452  msk         500.0  4.538813  30776 30770   \n",
              "4  13418544315327784420  msk         500.0  4.409091        31495   \n",
              "\n",
              "                                         features_id  \n",
              "0  3501685156 3501779478 20422 3502045016 3502045...  \n",
              "1  1509 1082283206 273469383 10462 11617 35017794...  \n",
              "2  10462 11177 11617 11629 1416 1018 11704 11867 ...  \n",
              "3  3501618484 2020795524 11629 11617 1018 11704 2...  \n",
              "4  11617 10462 11177 1416 11867 3501744275 20282 ...  "
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN9kZbURGH64"
      },
      "source": [
        "Полезно посмотреть внимательнее на то, с какими признаками нам предстоит работать.\n",
        "\n",
        "* **org_id** вам не понадобится;\n",
        "* **city** - город, в котором находится заведение (``msk`` или ``spb``);\n",
        "* **average_bill** - средний чек в заведении - он будет нашим таргетом;\n",
        "* **rating** - рейтинг заведения;\n",
        "* **rubrics_id** - тип заведения (или несколько типов). Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``rubrics``\n",
        "* **features_id** - набор неких фичей заведения. Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``features``\n",
        "\n",
        "Обратите внимание, что **rubrics_id** и **features_id** - это не списки, а разделённые пробелами строки. Когда вам захочется работать с отдельными фичами из мешка фичей для данного заведения, вам придётся всё-таки превратить их в списки (здесь поможет метод `split` для строк)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0IJIWz3GH64"
      },
      "source": [
        "Чтобы быстро восстанавливать по рубрикам и фичам их нормальные названия, сделайте словари вида ``код_фичи:название_фичи``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "8KwKEKr7GH65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{30519: 'Булочная, пекарня',\n",
              " 30770: 'Бар, паб',\n",
              " 30771: 'Быстрое питание',\n",
              " 30774: 'Кафе',\n",
              " 30775: 'Пиццерия',\n",
              " 30776: 'Ресторан',\n",
              " 30777: 'Столовая',\n",
              " 31286: 'Спортбар',\n",
              " 31350: 'Кондитерская',\n",
              " 31375: 'Суши-бар',\n",
              " 31401: 'Кальян-бар',\n",
              " 31495: 'Кофейня',\n",
              " 3108292683: 'Бар безалкогольных напитков',\n",
              " 3501514558: 'Фудкорт',\n",
              " 3501750896: 'Кофе с собой'}"
            ]
          },
          "execution_count": 260,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.head()\n",
        "features = features.set_index('feature_id')\n",
        "feature_dict = features.to_dict()\n",
        "feature_dict = feature_dict['feature_name']\n",
        "feature_dict\n",
        "\n",
        "rubrics = rubrics.set_index('rubric_id')\n",
        "rubric_dict = rubrics.to_dict()\n",
        "rubric_dict = rubric_dict['rubric_name']\n",
        "rubric_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNd4PkyQGH65"
      },
      "source": [
        "Посмотрим, какими бывают типы заведений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "8WhaPPEeGH65",
        "outputId": "aaf9cc8c-64ae-4bac-d8f8-6dd4d03033d8",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{30519: 'Булочная, пекарня',\n",
              " 30770: 'Бар, паб',\n",
              " 30771: 'Быстрое питание',\n",
              " 30774: 'Кафе',\n",
              " 30775: 'Пиццерия',\n",
              " 30776: 'Ресторан',\n",
              " 30777: 'Столовая',\n",
              " 31286: 'Спортбар',\n",
              " 31350: 'Кондитерская',\n",
              " 31375: 'Суши-бар',\n",
              " 31401: 'Кальян-бар',\n",
              " 31495: 'Кофейня',\n",
              " 3108292683: 'Бар безалкогольных напитков',\n",
              " 3501514558: 'Фудкорт',\n",
              " 3501750896: 'Кофе с собой'}"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rubric_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6Bm_8EGH66"
      },
      "source": [
        "Мы что-то поняли про признаки, которыми нам предстоит пользоваться. Теперь время посмотреть на таргет. Вооружившись функциями ``hist`` и ``scatter`` из библиотеки ``matplotlib``, а также методом ``isna`` для pandas-таблиц разберитесь, какие значения принимают таргеты, есть ли там там выбросы, пропуски или ещё какие-то проблемы.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>Среди таргетов довольно много пропусков;</li>\n",
        "      <li>Все таргеты - это числа, кратные 500;</li>\n",
        "      <li>Есть какие-то адские значения, превышающие 100 000 (видимо, выбросы);</li>\n",
        "      <li>В целом, число ресторанов с данным средним чеком быстро падает с ростом среднего чека. Для средних чеков, больших 2500, заведений уже совсем мало. Примерно у 2/3 заведений средний чек 500.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "average_bill\n",
              "500.0       22329\n",
              "1000.0       5482\n",
              "1500.0       2696\n",
              "2000.0       1184\n",
              "2500.0        445\n",
              "            ...  \n",
              "60000.0         1\n",
              "12000.0         1\n",
              "25500.0         1\n",
              "250000.0        1\n",
              "101500.0        1\n",
              "Name: count, Length: 63, dtype: int64"
            ]
          },
          "execution_count": 262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.average_bill = data.average_bill.map(float)\n",
        "data.average_bill.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "f6bg-kmIGH66",
        "outputId": "69beeb66-b7aa-4905-bc73-59a6ab27edf3",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='average_bill', ylabel='count'>"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.head()\n",
        "data.average_bill.hist()\n",
        "\n",
        "sns.countplot(data=data, x='average_bill')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trfl5F_4GH66"
      },
      "source": [
        "**Базовая очистка данных**\n",
        "\n",
        "Раз есть треш, давайте чистить данные.\n",
        "\n",
        "С пропусками можно бороться по-разному (даже и с пропусками в таргете), но пока мы сделаем самую простую вещь: дропнем все заведения, для которых мы не знаем средний чек.\n",
        "\n",
        "Уберите из них все заведения, у которых средний чек неизвестен или превышает 2500. Пока есть опасение, что их слишком мало, чтобы мы смогли обучить на них что-нибудь.\n",
        "\n",
        "**3. Введите в Контест количество заведений, которое у вас получилось после очистки**.\n",
        "\n",
        "Дальше мы будем работать с очищенными данными."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "OxIkRsA1GH67"
      },
      "outputs": [],
      "source": [
        "data = data.dropna(subset=['average_bill'])\n",
        "clean_data = data[data.average_bill <= 2500]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNzGAp1GH67"
      },
      "source": [
        "**4. Посчитайте и введите в Контест разность между средними арифметическими average_bill в кафе Москвы и Санкт-Петербурга. Округлите ответ до целого.**\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Небольшая подсказка</summary>\n",
        "  Примените часто используемый метод groupby.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "gLdl3zVCGH67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(735.7469646313567)"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby('city').average_bill.mean().loc['spb']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qncnmi8bGH7F"
      },
      "source": [
        "Давайте ещё немного поизучаем данные. Ответьте на вопросы:\n",
        "\n",
        "1. Есть ли разница между средними чеками в Москве и Санкт-Петербурге?\n",
        "2. Коррелирует ли средний чек с рейтингом?\n",
        "3. Есть ли разница в среднем чеке между ресторанами и пабами (см. соответствующие типы из ``rubrics``)?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>В целом, да. Вы могли бы сравнить средние (в Москве больше) или медианы (они равны, потому что уж больно много где средний чек 500). Этого, конечно, мало для того, чтобы сделать вывод. Нужно проверять какие-то статические критерии, которые изучаются в курсе по статистике. Не будем останавливаться на этом подробно. Поскольку данные совсем не нормальные, никакой t-тест не сработает; мы бы предложили использовать критерий Манна-Уитни (см. википедию и функцию mannwhitneyu из библиотеки scipy.stats).</li>\n",
        "      <li>Какая-то корреляция между ними есть но уж больно неубедительная (рекомендуем построим на одном графике boxplot рейтинга по каждому значению среднего чека для визуализации). Конечно, дна становится меньше с ростом среднего чека, но, видимо, в предсказании это особо не используешь;</li>\n",
        "      <li>Несомненно, в ресторанах средний чек выше. Это и невооружённым глазом видно, и с помощью критерия Манна-Уитни можно проверить.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='average_bill', ylabel='rating'>"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.scatterplot(data=data, x='average_bill', y='rating', hue='city')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATY5075lGH7F"
      },
      "source": [
        "## Формулируем задачу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpEgJGIGH7F"
      },
      "source": [
        "Прежде, чем решать задачу, её надо сформулировать.\n",
        "\n",
        "**Вопрос первый**: это классификация или регрессия? Подумайте над этим.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    Ответ не столь однозначен, как хотелось бы. С одной стороны, таргет принимает всего четыре значения, и потому это может быть классификацией с 4 классами. С другой стороны, таргеты - это не абстрактные \"треугольник\", \"круг\", \"квадрат\", а вещественные числа, и когда мы вместо 500 предсказываем 2500, это явно хуже, чем вместо 1500 предсказать 2000. В целом, задачу можно решать и так, и так; мы будем смотреть на метрики обеих задач.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVuazxsGH7G"
      },
      "source": [
        "**Вопрос второй**: какие метрики мы будем использовать для оценки качества решения? Какие метрики вы предложили бы для этой задачи как для задачи классификации? А для этой задачи, как для задачи регрессии?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Начнём с классификации. Метрика accuracy не очень хороша из-за несбалансированности классов. Действительно, классификатор, который всегда говорит 500, будет иметь accuracy примерно 0.66, хотя это никак не отражает практическую ценность модели. Как мы увидим, самая большая проблема будет заключаться в том, чтобы научиться выделять заведения с большими чеками, а их меньше всего и в accuracy они вносят самый маленький вклад. Есть разные способы с этим бороться, один -- использовать sklearn.metrics.balanced_accuracy_score. Его идея, грубо говоря, в том, чтобы по каждому классу найти, какая доля объектов этого класса правильно классифицирована, а потом эти доли усреднить. Тогда у бессмысленного классификатора, который всем ставит 500, будет скор 1/5 (ведь классов 5), а чтобы получить прежние 2/3, нужно будет научиться в каждом классе правильно ставить хотя бы 2/3 меток.    \n",
        "    \n",
        "    Теперь что касается регрессии. Основых метрики две - MSE и MAE. Из первой стоит извлекать корень, чтобы получать интерпретируемые человеком значения, а вторая менее агрессивна к выбросам (впрочем, выбросов тут уже нет, мы их все выкинули). Без дополнительной информации не очень понятно, какую выбирать, можно брать любую. А выбирать надо: ведь даже банальные модели \"предсказывай всегда среднее\" и \"предсказывай всегда медиану\" будут по-разному ранжироваться этими метриками.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs-jkCj-GH7G"
      },
      "source": [
        "**Вопрос третий**: а не взять ли нам какую-нибудь более экзотическую метрику? Например, MAPE (определение в учебнике в главе про оценку качества моделей). А как вам такое соображение: допустим, заказчик говорит, что пользователи будут расстраиваться, только если мы завысили средний чек - так давайте поправим MSE или MAE, обнуляя те слагаемые, для которых предсказанный таргет меньше истинного. Вот это хорошая метрика или нет?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Что касается MAPE, у нас нет тех проблем, с которой она борется. Вот если бы у нас были средние чеки от 500 до миллиона, мы бы столкнулись с ситуацией, что большие ошибки для больших чеков доминировали бы в сумме для MSE и MAE (500 вместо 1000 меркнет по сравнению с 500к вместо миллиона). Говоря поэтически, мы бы оптимизировали модель для миллионеров, забыв про простых трудяг. И было бы логично перейти от парадигмы \"ошибаемся на 500 рублей\" к парадигме \"ошибаемся на 50%\". Но у нас все таргеты примерно одного порядка, MAPE нам особо ни к чему.\n",
        "    \n",
        "    Вторая метрика коварна тем, что её можно \"накрутить\" безо всякой пользы для дела. А именно, модель, которая всегда предсказывает средний чек в миллион, была бы идеальна. Но все бы расстраивались и не ходили есть. Другое дело, что можно ввести разные веса для ошибок в большую и в меньшую сторону, но опять же - пока нет показаний к тому, что это нужно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjV_SoAGH7G"
      },
      "source": [
        "## Применяем ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkvcLSPGH7G"
      },
      "source": [
        "Теперь время разбить данные на обучающую и тестовую выборку. Делается это с помощью функции ``train_test_split`` из пакета ``sklearn``. При этом очень важно сделать две вещи:\n",
        "\n",
        "* Зафиксировать ``random_state=42`` (да, именно этот, а то ваши модели могут не зайти в Контест), чтобы всё, что мы делаем, было воспроизводимо (иначе от перезапуска к перезапуску числа могут меняться, и мы не будем понимать, из-за чего это происходит).\n",
        "* Сделать стратификацию по таргету. В противном случае у нас в трейне и тесте могут оказаться разные пропорции классов (обычно особенно страдают мало представленные классы), что неутешительно скажется на результате.\n",
        "\n",
        "**Обратите внимание**, что если вы побьёте выборку на train и test по-другому, ваши результаты могут не зайти в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "AF2IVpOjGH7H"
      },
      "outputs": [],
      "source": [
        "clean_data_train, clean_data_test = train_test_split(\n",
        "    clean_data, stratify=clean_data['average_bill'], test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S161veFJGH7H"
      },
      "source": [
        "Теперь нам нужен **бейзлайн** - очень простая модель, с которой мы в дальнейшем будем сравниваться.\n",
        "\n",
        "Поскольку мы ещё не знаем никаких умных классов моделей, все модели мы будем писать руками. А именно, мы напишем две простых модели на основе ``sklearn.baseRegressorMixin`` и ``sklearn.base.ClassifierMixin`` (посмотрите примеры в документации sklearn и сделайте так же):\n",
        "\n",
        "* Модель для задачи регрессии, которая для всех заведений предсказывает одно число — среднее значение среднего чека;\n",
        "* Модель для задачи классификации, которая для всех заведений предсказывает один класс — самый частый класс (ироничным образом он в данном случае совпадает с медианой).\n",
        "\n",
        "**Важно!** Мы будем много раз повторять вам мантру о том, что **информация из тестовой выборки не должна протекать в процесс обучения**. Так вот, и среднее, и самый частый класс вы должны считать именно на обучающей выборке!\n",
        "\n",
        "**5 и 6. Напишите эти две модели и сдайте в Контест**. В процессе проверки модели будут и обучаться, и предсказывать.\n",
        "\n",
        "Заметим, что для этих моделей нам вообще не нужны какие-то \"фичи\"; мы работаем только с таргетом.\n",
        "\n",
        "У каждой модели есть (как минимум) два метода: `fit` (обучает модель по фичам `X` и таргету `y`) `predict` (предсказывает по фичам `X`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "lLz_sxtUGH7H"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class MeanRegressor(RegressorMixin):\n",
        "    # Predicts the mean of y_train\n",
        "\n",
        "    def __init__(self):\n",
        "        self._mean = None\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        self._mean = y.mean()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        return np.full(X.shape[0], self._mean)\n",
        "\n",
        "from sklearn.base import ClassifierMixin\n",
        "\n",
        "class MostFrequentClassifier(ClassifierMixin):\n",
        "    # Predicts the rounded (just in case) median of y_train\n",
        "    def __init__(self):\n",
        "        self._median = None\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        self._median = np.median(y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        return np.full(X.shape[0], np.round(self._median))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2pNhVoGH7I"
      },
      "source": [
        "Обучим наши модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "arXlaGnTGH7I"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.MostFrequentClassifier at 0x1462aaa80>"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg = MeanRegressor()\n",
        "reg.fit(y=clean_data_train['average_bill'])\n",
        "\n",
        "clf = MostFrequentClassifier()\n",
        "clf.fit(y=clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_reg: 448.71, Balanced Accuracy: 0.20, RMSE_clf: 514.75\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "pred_reg = reg.predict(clean_data_test[['average_bill']])\n",
        "pred_clf = clf.predict(clean_data_test[['average_bill']])\n",
        "rmse_reg = np.sqrt(mean_squared_error(clean_data_test['average_bill'], pred_reg))\n",
        "rmse_clf = np.sqrt(mean_squared_error(clean_data_test['average_bill'], pred_clf))\n",
        "bal_acc = balanced_accuracy_score(clean_data_test['average_bill'], pred_clf)\n",
        "print(f\"RMSE_reg: {rmse_reg:.2f}, Balanced Accuracy: {bal_acc:.2f}, RMSE_clf: {rmse_clf:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJG8x0tmGH7I"
      },
      "source": [
        "Обучите модели и оцените их качество на тестовой выборке. В качестве метрик возьмём RMSE (``np.sqrt`` от ``sklearn.metrics.mean_squared_error``) и ``sklearn.metrics.balanced_accuracy_score``.\n",
        "\n",
        "Для регрессионной модели имеет смысл считать только RMSE (значения будут не кратны 500, точно мы угадывать не будем никогда), а вот для классификационной можно найти обе метрики. Сделайте это. Какая модель оказалась лучше по RMSE?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvZwp54sGH7J"
      },
      "source": [
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда</summary>\n",
        "    \n",
        "  Казалось бы, регрессор никогда не угадывает, но он в каком-то смысле лучше классификатора - справедливо ли это? Возможно. Несуществующий пользователь модели вряд ли будет задавать вопросы \"почему средний чек не кратен 500?\" Ну, выдали около 800 - ок, понятно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-1-O9GyGH7J"
      },
      "source": [
        "## Усложнение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGWgxl0VGH7J"
      },
      "source": [
        "Бейзлайны будут нашей отправной точкой. Строя дальнейшие модели, мы будем спрашивать себя: получилось ли лучше бейзлайна? Если нет или если не особо, то в чём смысл усложнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3DkuuFGH7K"
      },
      "source": [
        "Начнём с использования фичи ``city``. Мы уже видели, что в разных городах и средние чеки разные. Легко проверить, что *медиана* средних чеков всё же одна и та же и в Москве, и в Санкт-Петербурге (ох уж этот вездесущий средний чек 500!), поэтому с классификатором мы ничего не сделаем. Но вот регрессор можно попробовать починить.\n",
        "\n",
        "**7. Напишите регрессор, для каждого заведения предсказывающий среднее значение в том же городе (на обучающей выборке, конечно) и сдайте его в Контест**. Вам может помочь то, что булевы `pandas` и `numpy` столбцы можно умножать на численные — в такой ситуации False работает, как ноль, а True как единица."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "ZULQVPe2GH7K"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class CityMeanRegressor(RegressorMixin):\n",
        "    def __init__(self):\n",
        "        self.msk_mean = None\n",
        "        self.spb_mean = None\n",
        "    def fit(self, X:pd.DataFrame=None, y:pd.DataFrame=None):\n",
        "        self.msk_mean = X.groupby('city').average_bill.mean().loc['msk']\n",
        "        self.spb_mean = X.groupby('city').average_bill.mean().loc['spb']\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        X.loc[X['city'] == 'spb', 'average_bill'] = self.spb_mean\n",
        "        X.loc[X['city'] == 'msk', 'average_bill'] = self.msk_mean\n",
        "        return X['average_bill'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(445.10632814032624)"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_reg = CityMeanRegressor()\n",
        "mean_reg.fit(clean_data_train, clean_data_train['average_bill'])\n",
        "pred_mean_reg = mean_reg.predict(clean_data_test[['city', 'average_bill']])\n",
        "np.sqrt(mean_squared_error(clean_data_test['average_bill'], pred_mean_reg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EeFGk24GH7K"
      },
      "source": [
        "Обучите регрессор и сравните его по метрике RMSE с бейзлайнами. Получилось ли улучшить метрику?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jROycei1GH7L"
      },
      "source": [
        "Лучше стало, но, правда, не очень сильно. В этот момент очень важно не просто радовать руководителя приростом в третьем знаке, но и думать о том, что происходит.\n",
        "\n",
        "Средний средний чек по Москве равен 793, в Санкт-Петербурге - 676, а в целом - 752 рубля. MSE, увы, не поможет вам ответить на вопрос, стало ли лучше пользователю, если вы ему вместо 752 рублей назвали 793. Здесь вскрывается весьма существенный порок MSE в этой задаче. Дело в том, что наш изначальный таргет делит заведения на некоторые \"ценовые категории\", и различие в средних чеках 500 и 1000 в самом деле существенно. Наверное, мы хотели бы как раз правильно предсказывать ценовые категории. Но MSE не очень помогает нам об этом судить. Дальше мы ещё подумаем, как это исправить.\n",
        "\n",
        "В любом случае, несмотря на улучшение метрики, мы пока не можем судить, стало ли по жизни лучше от усложнения модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEQ9eOoWGH7L"
      },
      "source": [
        "Поручинившись немного, возьмём на вооружение другую идею. Давайте использовать типы заведений!\n",
        "\n",
        "Но с типами есть некоторая проблема: в столбце ``rubrics_id`` не всегда один идентификатор, часто их несколько, и всего комбинаций довольно много. Чтобы не возиться с малочисленными типами, давайте сольём их в один безликий ``other``.\n",
        "\n",
        "Итак, добавьте в обучающие и тестовые данные столбец ``modified_rubrics``, в котором будет то же, что и в ``rubrics_id``, если соответствующая комбинация рубрик содержит хотя бы 100 заведений из обучающей (!) выборки, и строка ``other`` в противном случае.\n",
        "\n",
        "Здесь вам поможет контейнер ``Counter`` из библиотеки ``collections``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "uTVW5KkwGH7L"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kg/d5rbc3413tb542__t6bc7bn40000gn/T/ipykernel_25764/2635444181.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data.loc[:,'modified_rubrics'] = clean_data['rubrics_id'].apply(map_rubric)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "rubric_counts = clean_data['rubrics_id'].value_counts()\n",
        "valid_rubrics = rubric_counts[rubric_counts >= 100].index\n",
        "\n",
        "def map_rubric(rubric):\n",
        "    return rubric if rubric in valid_rubrics else 'other'\n",
        "\n",
        "clean_data.loc[:,'modified_rubrics'] = clean_data['rubrics_id'].apply(map_rubric)\n",
        "\n",
        "clean_data_train, clean_data_test = train_test_split(\n",
        "    clean_data, stratify=clean_data['average_bill'], test_size=0.33, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZXhpBjnGH7L"
      },
      "source": [
        "Теперь настало время написать могучий классификатор, который по заведению предсказывает медиану средних чеков среди тех в обучающей выборке, у которых с ним одинаковые `modified_rubrics` и город (вы спросите, почему медиану, а не самый частый -- спишем это на вдохновение; самый частый тоже можно брать - но медиана работает лучше).\n",
        "\n",
        "**8. Напишите классификатор и сдайте в Контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "eTfcwh5dGH7M"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class MostFrequentRubricRegressor(RegressorMixin):\n",
        "    def __init__(self):\n",
        "        self.medians = None\n",
        "\n",
        "    def fit(self, X=None, y=None):\n",
        "        self.medians = X.groupby(['city', 'modified_rubrics']).average_bill.median().to_dict()\n",
        "        return self\n",
        "    def predict(self, X=None):\n",
        "        X.loc[:,'average_bill'] = X.apply(\n",
        "            lambda row: self.medians.get((row['city'], row['modified_rubrics']), np.nan), axis=1)\n",
        "        return X['average_bill'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE_my_reg: 391.84\n",
            "Balanced Accuracy: 0.31\n",
            "500.0: 6589 1000.0: 721 1500.0: 217 \n",
            "\n",
            "500.0: 1223 1000.0: 1248 1500.0: 607 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kg/d5rbc3413tb542__t6bc7bn40000gn/T/ipykernel_25764/3160338782.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.loc[:,'average_bill'] = X.apply(\n"
          ]
        }
      ],
      "source": [
        "my_reg = MostFrequentRubricRegressor()\n",
        "my_reg.fit(clean_data_train, clean_data_train['average_bill'])\n",
        "pred_my_reg = my_reg.predict(clean_data_test[['city', 'modified_rubrics']])\n",
        "\n",
        "rmse_my_reg = np.sqrt(mean_squared_error(clean_data_test['average_bill'], pred_my_reg))\n",
        "print(f\"RMSE_my_reg: {rmse_my_reg:.2f}\")\n",
        "bal_acc = balanced_accuracy_score(clean_data_test['average_bill'], pred_my_reg)\n",
        "print(f\"Balanced Accuracy: {bal_acc:.2f}\")\n",
        "\n",
        "mask = (pred_my_reg == clean_data_test['average_bill'])\n",
        "correct_predictions = pred_my_reg[mask]\n",
        "incorrect_predictions = pred_my_reg[~mask]\n",
        "\n",
        "for i in np.unique(correct_predictions):\n",
        "    print(f\"{i}: {np.count_nonzero(correct_predictions == i)}\", end=' ')\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "for i in np.unique(correct_predictions):\n",
        "    print(f\"{i}: {np.count_nonzero(incorrect_predictions == i)}\", end=' ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgjbwgkGH7M"
      },
      "source": [
        "Сравните обученный классификатор по метрикам RMSE и balanced_accuracy_score с нашими бейзлайнами. Получилось ли улучшить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMjsnCnQGH7M"
      },
      "source": [
        "Обратите внимание что рост accuracy по сравнению с бейзлайном при этом на порядок меньше:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2cF0I-CGH7M"
      },
      "source": [
        "accuracy_score\n",
        "\n",
        "Predict most frequent:  0.6947666195190948\n",
        "\n",
        "Predict by rubric and city:  0.7095709570957096"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylrAIjCcGH7N"
      },
      "source": [
        "Для диагностики напечатайте для каждого класса тестовой выборки, сколько в нём объектов и скольким из них наш классификатор приписал правильный класс. Что вы видите?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "  Вы, вероятно, видите то, что мы стали однозначно лучше по сравнению с бейзлайном детектировать средний чек 1000 и 1500 (хотя всё равно не очень хорошо + ценой ухудшения качества на среднем чеке 500), а вот чеки 2000 и 2500 нам ну никак не даются.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ScOy7ZvGH7N"
      },
      "source": [
        "**Кстати**. А вы понимаете, почему приведённый выше пайплайн классификации был не очень удачным с точки зрения архитектуры? Почему его было бы правильнее воплотить по-другому?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "Собственно говоря, и не было никакого пайплайна. К счастью, у нас была одна обучающая выборка, мы на ней посчитали список рубрик для modified_rubrics и радовались жизни. Но если бы нам надо было переобучать всё на новых данных, пришлось бы помнить, что их надо везде пересчитать (ведь у нас могли появиться новые рубрики с хотя бы 100 представителями). А уж никакую кросс-валидацию (кто знает - тот поймёт) с нашим подходом к делу и вовсе бы не получилось сделать без боли.\n",
        "    \n",
        "Поэтому в следующей лабораторной вы научитесь делать честные пайплайны, в которых преобразование данных, генерация фичей и обучение классификатора будут объединены в один понятный процесс, происходящий на этапе fit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ujl3tbbGH7N"
      },
      "source": [
        "## Слишком простые и слишком сложные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF7McCHsGH7N"
      },
      "source": [
        "Бейзлайны у нас слишком просты и потому не очень полезны в жизни. Но если сложность модели растёт бесконтрольно, то тоже получается плохо.\n",
        "\n",
        "Давайте рассмотрим конкретный пример. Создадим классификатор, использующий одновременно `rubrics_id` и `features_id`.\n",
        "\n",
        "Сделайте следующее:\n",
        "\n",
        "- для каждого объекта обучающей выборки сконкатенируйте строку `rubrics_id` с разделителем (например, буквой 'q') и содержимым `features_id`. Полученный столбец озаглавьте `modified_features`. Это не самый клёвый способ заиспользовать все фичи, но сейчас пока сойдёт. Причём на сей раз не будем выкидывать мало представленные значения (вся информация важна, не так ли?).\n",
        "- при этом для тестовой выборке заменяйте на строку `other` все конкатенации, которые не встретились в обучающей выборке.\n",
        "\n",
        "То есть элементы в этом столбце будут иметь вид `other` или `30776 30774 q 3502045032 11741 3502045016 1046...`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8tNBPzVGH7O"
      },
      "source": [
        "Теперь обучите классификатор, который для заведения предсказывает медиану среднего чека по всем объектам тестовой выборки с таким же, как у него, значением `modified_features`, а если такого в обучающей выборке нет, то глобальную медиану среднего чека по всей обучающей выборке.\n",
        "\n",
        "**9. Загрузите в Контест предсказания этого классификатора на тестовой выборке**\n",
        "\n",
        "Мы ждём файла **.csv**, у которого в каждой строке будет только одно число - предсказание классификатора.\n",
        "\n",
        "Возможно, вам будет полезна библиотека ``tqdm``, позволяющая отслеживать в реальном времени, сколько времени уже крутится цикл и сколько итераций ещё осталось. Впрочем, если вы всё написали нормально, то должно работать не очень долго."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XrswPW4GH7O"
      },
      "source": [
        "Модель, очевидно, очень сложная. Число параметров (различных категорий) в ней сопоставимо с числом объектов в обучающей выборке. А получилось ли хорошо?\n",
        "\n",
        "Давайте посчитаем RMSE и balanced_accuracy_score на обучающей и на тестовой выборках.\n",
        "\n",
        "**10. Введите их в Контест**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDTpxFgGH7O"
      },
      "source": [
        "Налицо переобучение: на трейне метрики отличные, на тесте - вообще никакие\n",
        "\n",
        "В общем, не гонитесь за чрезмерной сложностью модели.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTU2yubYGH7O"
      },
      "source": [
        "## ML без данных что компутер без электричества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVOCVf2GH7P"
      },
      "source": [
        "Возможно, вы смотрите на полученные выше результаты и думаете: вот если бы мы не какие-то убогие медианы предсказывали, а гоняли бы нейросети, то тут-то бы всё и получилось!\n",
        "\n",
        "Но, увы, совсем даже не всегда от счастья нас отделяет выбор хорошей модели (и стратегии обучения). Если данные не очень, то даже самая крутая модель не сработает. В этой ситуации нужно либо добывать новые фичи каким-то образом, либо собирать новые данные (увеличивать датасет), либо просто бросать задачу.\n",
        "\n",
        "Давайте посмотрим, что выжмет из наших данных одна из самых мощных моделей для табличных данных - градиентный бустинг на решающих деревьях в исполнении [CatBoost](https://catboost.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0L4UmzSGH7P"
      },
      "source": [
        "Но прежде, чем сделать fit, нам надо облагородить данные. Несмотря на то, что CatBoost отлично работает с категориальными фичами, мешок признаков из `rubrics_id` или `features_id` может ему оказаться не по зубам. Поэтому мы соберём датасет в пристойную матрицу, создав для каждого типа рубрик и фичей отдельный столбец и записав там единицы для тех объектов, у которых эта рубрика или фича имеет место.\n",
        "\n",
        "В матрице почти все элементы будут нулями. Такие матрицы считаются **разреженными** и их можно хранить гораздо эффективней, чем просто таблицей. Этим и займёмся)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJKuMtNbGH7P"
      },
      "source": [
        "Есть несколько форматов хранения разреженных матриц (многие из них реализованы в [пакете sparse библиотеки scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), и каждый пригоден для чего-то своего.\n",
        "\n",
        "Создавать разреженную матрицу лучше в [формате COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array). Он предполагает, что разреженная матрица задаётся в виде трёх списков: `row`, `col`, `data`, причём каждая тройка `(row[i], col[i], data[i])` кодирует элемент со значением `data[i]`, стоящий на позиции `(row[i], col[i])`. Считается, что на позициях `(row, col)`, которые ни разу не встретились, стоят нули.\n",
        "\n",
        "Нетрудно видеть, что заполнять такую матрицу - одно удовольствие, и особенно этому помогает тот факт, что **пара `(row, col)` может встретиться несколько раз** (тогда в итоговой матрице на соответствующей позиции стоит сумма соответствующих `data[i]`). Но, с другой стороны, почти ничего другого с такой матрицей не сделаешь: произвольного доступа к элементам она не предоставляет, умножить её тоже особо ничего не умножишь. Поэтому для дальнейшего использования созданную таким образом матрицу преобразуют в один из более удобных форматов, например, [CSR (compressed sparse row)](https://scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html). Он, к примеру, хорошо подходит для умножения на вектор (потому что матрица хранится по строкам). Не будем разбирать его подробно, но можете почитать по ссылке, если интересно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_Sob3GH7P"
      },
      "source": [
        "Вам нужно будет превратить обучающие и тестовые данные в разреженные матрицы `sparse_data_train` и `sparse_data_test` соответственно, таким образом, что:\n",
        "\n",
        "- столбец `city` превратится в столбец из единиц и нулей (например, 1 - Москва, 0 - Питер);\n",
        "- столбец `rating` перекочует в разреженные матрицы без изменений;\n",
        "- каждый типы рубрик и каждая фича превратятся в отдельный 0-1-принак;\n",
        "\n",
        "В тестовой выборке будут фичи, которых в обучающей выборке не было. С ними можно по-разному работать, но давайте создадим дополнительную фантомную фичу `feature_other`, в которой будет то, сколько неизвестных по обучающей выборке фичей есть у данного объекта."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "7-UAatGJGH7P"
      },
      "outputs": [],
      "source": [
        "sparse_data_train : pd.DataFrame = clean_data_train.copy()\n",
        "sparse_data_train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "features_encoded = sparse_data_train['features_id'].str.get_dummies(sep=' ')\n",
        "unique_features = features_encoded.columns\n",
        "sparse_data_train = pd.concat([sparse_data_train, features_encoded], axis=1)\n",
        "\n",
        "rubrics_encoded = sparse_data_train['rubrics_id'].str.get_dummies(sep=' ')\n",
        "sparse_data_train = pd.concat([sparse_data_train, rubrics_encoded], axis=1)\n",
        "\n",
        "sparse_data_train['city'] = sparse_data_train['city'].apply(lambda x: 0 if x == 'msk' else 1 if x == 'spb' else x)\n",
        "\n",
        "sparse_data_train.loc[:, 'feature_other'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "sparse_data_test : pd.DataFrame = clean_data_test.copy()\n",
        "sparse_data_test['city'] = sparse_data_test['city'].apply(lambda x: 0 if x == 'msk' else 1 if x == 'spb' else x)\n",
        "sparse_data_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "features_encoded = sparse_data_test['features_id'].str.get_dummies(sep=' ')\n",
        "sparse_data_test = pd.concat([sparse_data_test, features_encoded], axis= 1)\n",
        "\n",
        "rubrics_encoded = sparse_data_test['rubrics_id'].str.get_dummies(sep=' ')\n",
        "sparse_data_test = pd.concat([sparse_data_test, rubrics_encoded], axis= 1)\n",
        "\n",
        "sparse_data_test['features_id'] = sparse_data_test['features_id'].str.split(' ')\n",
        "\n",
        "unique_features = set(unique_features)\n",
        "def count_unknown_features(feature_list):\n",
        "    return sum(1 for f in feature_list if f not in unique_features)\n",
        "\n",
        "sparse_data_test['feature_other'] = sparse_data_test['features_id'].apply(count_unknown_features)\n",
        "sparse_data_test.drop(columns=['features_id', 'rubrics_id', 'modified_rubrics', 'org_id'], inplace=True)\n",
        "sparse_data_train.drop(columns=['features_id', 'rubrics_id', 'modified_rubrics', 'org_id'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10605, 606), (21531, 606))"
            ]
          },
          "execution_count": 287,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sparse_data_test = sparse_data_test.reindex(columns=sparse_data_train.columns)\n",
        "sparse_data_test = sparse_data_test.fillna(0)\n",
        "\n",
        "sparse_data_test.shape, sparse_data_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfj-1E4GH7Q"
      },
      "source": [
        "Данные готовы, и теперь можно запустить катбуст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "m2lP5NouGH7Q"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "jpW6uR0oGH7Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.092536\n",
            "0:\tlearn: 1.2592622\ttotal: 50.9ms\tremaining: 50.9s\n",
            "1:\tlearn: 1.0425367\ttotal: 225ms\tremaining: 1m 52s\n",
            "2:\tlearn: 0.8856635\ttotal: 317ms\tremaining: 1m 45s\n",
            "3:\tlearn: 0.7601849\ttotal: 366ms\tremaining: 1m 31s\n",
            "4:\tlearn: 0.6601409\ttotal: 407ms\tremaining: 1m 20s\n",
            "5:\tlearn: 0.5777936\ttotal: 460ms\tremaining: 1m 16s\n",
            "6:\tlearn: 0.5088852\ttotal: 500ms\tremaining: 1m 10s\n",
            "7:\tlearn: 0.4520989\ttotal: 543ms\tremaining: 1m 7s\n",
            "8:\tlearn: 0.4017313\ttotal: 586ms\tremaining: 1m 4s\n",
            "9:\tlearn: 0.3581720\ttotal: 641ms\tremaining: 1m 3s\n",
            "10:\tlearn: 0.3202792\ttotal: 702ms\tremaining: 1m 3s\n",
            "11:\tlearn: 0.2870379\ttotal: 757ms\tremaining: 1m 2s\n",
            "12:\tlearn: 0.2578305\ttotal: 803ms\tremaining: 1m\n",
            "13:\tlearn: 0.2319516\ttotal: 841ms\tremaining: 59.2s\n",
            "14:\tlearn: 0.2089632\ttotal: 884ms\tremaining: 58.1s\n",
            "15:\tlearn: 0.1885016\ttotal: 938ms\tremaining: 57.7s\n",
            "16:\tlearn: 0.1702579\ttotal: 984ms\tremaining: 56.9s\n",
            "17:\tlearn: 0.1539335\ttotal: 1.02s\tremaining: 55.7s\n",
            "18:\tlearn: 0.1392944\ttotal: 1.06s\tremaining: 54.6s\n",
            "19:\tlearn: 0.1261486\ttotal: 1.1s\tremaining: 53.8s\n",
            "20:\tlearn: 0.1143838\ttotal: 1.14s\tremaining: 53s\n",
            "21:\tlearn: 0.1037632\ttotal: 1.19s\tremaining: 52.9s\n",
            "22:\tlearn: 0.0941693\ttotal: 1.23s\tremaining: 52.2s\n",
            "23:\tlearn: 0.0855078\ttotal: 1.27s\tremaining: 51.6s\n",
            "24:\tlearn: 0.0776842\ttotal: 1.31s\tremaining: 51s\n",
            "25:\tlearn: 0.0706121\ttotal: 1.35s\tremaining: 50.7s\n",
            "26:\tlearn: 0.0642089\ttotal: 1.39s\tremaining: 50.2s\n",
            "27:\tlearn: 0.0584299\ttotal: 1.45s\tremaining: 50.2s\n",
            "28:\tlearn: 0.0531852\ttotal: 1.49s\tremaining: 49.8s\n",
            "29:\tlearn: 0.0484349\ttotal: 1.53s\tremaining: 49.5s\n",
            "30:\tlearn: 0.0440999\ttotal: 1.57s\tremaining: 49.2s\n",
            "31:\tlearn: 0.0401648\ttotal: 1.64s\tremaining: 49.5s\n",
            "32:\tlearn: 0.0365940\ttotal: 1.68s\tremaining: 49.3s\n",
            "33:\tlearn: 0.0333509\ttotal: 1.75s\tremaining: 49.8s\n",
            "34:\tlearn: 0.0304060\ttotal: 1.91s\tremaining: 52.7s\n",
            "35:\tlearn: 0.0277292\ttotal: 2.03s\tremaining: 54.4s\n",
            "36:\tlearn: 0.0252957\ttotal: 2.09s\tremaining: 54.3s\n",
            "37:\tlearn: 0.0231117\ttotal: 2.16s\tremaining: 54.6s\n",
            "38:\tlearn: 0.0210914\ttotal: 2.28s\tremaining: 56.3s\n",
            "39:\tlearn: 0.0192937\ttotal: 2.44s\tremaining: 58.6s\n",
            "40:\tlearn: 0.0176204\ttotal: 2.54s\tremaining: 59.4s\n",
            "41:\tlearn: 0.0160980\ttotal: 2.61s\tremaining: 59.5s\n",
            "42:\tlearn: 0.0147237\ttotal: 2.71s\tremaining: 1m\n",
            "43:\tlearn: 0.0134573\ttotal: 2.76s\tremaining: 60s\n",
            "44:\tlearn: 0.0123357\ttotal: 2.83s\tremaining: 60s\n",
            "45:\tlearn: 0.0112866\ttotal: 2.88s\tremaining: 59.8s\n",
            "46:\tlearn: 0.0103261\ttotal: 2.95s\tremaining: 59.8s\n",
            "47:\tlearn: 0.0094523\ttotal: 3s\tremaining: 59.4s\n",
            "48:\tlearn: 0.0086546\ttotal: 3.06s\tremaining: 59.3s\n",
            "49:\tlearn: 0.0079284\ttotal: 3.14s\tremaining: 59.6s\n",
            "50:\tlearn: 0.0072674\ttotal: 3.2s\tremaining: 59.5s\n",
            "51:\tlearn: 0.0066756\ttotal: 3.24s\tremaining: 59.1s\n",
            "52:\tlearn: 0.0061257\ttotal: 3.27s\tremaining: 58.5s\n",
            "53:\tlearn: 0.0056240\ttotal: 3.32s\tremaining: 58.1s\n",
            "54:\tlearn: 0.0051643\ttotal: 3.35s\tremaining: 57.6s\n",
            "55:\tlearn: 0.0047466\ttotal: 3.39s\tremaining: 57.2s\n",
            "56:\tlearn: 0.0043657\ttotal: 3.48s\tremaining: 57.5s\n",
            "57:\tlearn: 0.0040181\ttotal: 3.52s\tremaining: 57.1s\n",
            "58:\tlearn: 0.0037006\ttotal: 3.56s\tremaining: 56.7s\n",
            "59:\tlearn: 0.0034342\ttotal: 3.6s\tremaining: 56.4s\n",
            "60:\tlearn: 0.0031682\ttotal: 3.64s\tremaining: 56.1s\n",
            "61:\tlearn: 0.0029249\ttotal: 3.69s\tremaining: 55.8s\n",
            "62:\tlearn: 0.0027179\ttotal: 3.74s\tremaining: 55.6s\n",
            "63:\tlearn: 0.0025133\ttotal: 3.78s\tremaining: 55.3s\n",
            "64:\tlearn: 0.0023264\ttotal: 3.85s\tremaining: 55.3s\n",
            "65:\tlearn: 0.0021601\ttotal: 3.92s\tremaining: 55.5s\n",
            "66:\tlearn: 0.0020038\ttotal: 3.96s\tremaining: 55.2s\n",
            "67:\tlearn: 0.0018604\ttotal: 4.04s\tremaining: 55.3s\n",
            "68:\tlearn: 0.0017307\ttotal: 4.11s\tremaining: 55.4s\n",
            "69:\tlearn: 0.0016105\ttotal: 4.22s\tremaining: 56s\n",
            "70:\tlearn: 0.0015003\ttotal: 4.29s\tremaining: 56.1s\n",
            "71:\tlearn: 0.0013993\ttotal: 4.37s\tremaining: 56.3s\n",
            "72:\tlearn: 0.0013180\ttotal: 4.44s\tremaining: 56.4s\n",
            "73:\tlearn: 0.0012322\ttotal: 4.5s\tremaining: 56.3s\n",
            "74:\tlearn: 0.0011597\ttotal: 4.56s\tremaining: 56.2s\n",
            "75:\tlearn: 0.0010865\ttotal: 4.61s\tremaining: 56s\n",
            "76:\tlearn: 0.0010196\ttotal: 4.65s\tremaining: 55.7s\n",
            "77:\tlearn: 0.0009578\ttotal: 4.7s\tremaining: 55.5s\n",
            "78:\tlearn: 0.0009011\ttotal: 4.74s\tremaining: 55.2s\n",
            "79:\tlearn: 0.0008490\ttotal: 4.77s\tremaining: 54.9s\n",
            "80:\tlearn: 0.0008009\ttotal: 4.81s\tremaining: 54.6s\n",
            "81:\tlearn: 0.0007566\ttotal: 4.86s\tremaining: 54.4s\n",
            "82:\tlearn: 0.0007157\ttotal: 4.91s\tremaining: 54.2s\n",
            "83:\tlearn: 0.0006778\ttotal: 4.94s\tremaining: 53.9s\n",
            "84:\tlearn: 0.0006429\ttotal: 4.98s\tremaining: 53.6s\n",
            "85:\tlearn: 0.0006106\ttotal: 5.02s\tremaining: 53.3s\n",
            "86:\tlearn: 0.0005806\ttotal: 5.05s\tremaining: 53s\n",
            "87:\tlearn: 0.0005677\ttotal: 5.08s\tremaining: 52.7s\n",
            "88:\tlearn: 0.0005409\ttotal: 5.12s\tremaining: 52.5s\n",
            "89:\tlearn: 0.0005167\ttotal: 5.17s\tremaining: 52.2s\n",
            "90:\tlearn: 0.0004945\ttotal: 5.21s\tremaining: 52s\n",
            "91:\tlearn: 0.0004767\ttotal: 5.23s\tremaining: 51.6s\n",
            "92:\tlearn: 0.0004681\ttotal: 5.26s\tremaining: 51.3s\n",
            "93:\tlearn: 0.0004517\ttotal: 5.29s\tremaining: 51s\n",
            "94:\tlearn: 0.0004442\ttotal: 5.32s\tremaining: 50.7s\n",
            "95:\tlearn: 0.0004374\ttotal: 5.34s\tremaining: 50.3s\n",
            "96:\tlearn: 0.0004343\ttotal: 5.37s\tremaining: 50s\n",
            "97:\tlearn: 0.0004242\ttotal: 5.4s\tremaining: 49.7s\n",
            "98:\tlearn: 0.0004217\ttotal: 5.42s\tremaining: 49.4s\n",
            "99:\tlearn: 0.0004195\ttotal: 5.47s\tremaining: 49.2s\n",
            "100:\tlearn: 0.0004031\ttotal: 5.55s\tremaining: 49.4s\n",
            "101:\tlearn: 0.0003892\ttotal: 5.64s\tremaining: 49.6s\n",
            "102:\tlearn: 0.0003812\ttotal: 5.67s\tremaining: 49.4s\n",
            "103:\tlearn: 0.0003736\ttotal: 5.71s\tremaining: 49.2s\n",
            "104:\tlearn: 0.0003600\ttotal: 5.76s\tremaining: 49.1s\n",
            "105:\tlearn: 0.0003563\ttotal: 5.79s\tremaining: 48.8s\n",
            "106:\tlearn: 0.0003552\ttotal: 5.83s\tremaining: 48.6s\n",
            "107:\tlearn: 0.0003542\ttotal: 5.85s\tremaining: 48.3s\n",
            "108:\tlearn: 0.0003480\ttotal: 5.88s\tremaining: 48.1s\n",
            "109:\tlearn: 0.0003472\ttotal: 5.91s\tremaining: 47.8s\n",
            "110:\tlearn: 0.0003465\ttotal: 5.93s\tremaining: 47.5s\n",
            "111:\tlearn: 0.0003373\ttotal: 5.98s\tremaining: 47.4s\n",
            "112:\tlearn: 0.0003320\ttotal: 6.03s\tremaining: 47.3s\n",
            "113:\tlearn: 0.0003269\ttotal: 6.05s\tremaining: 47.1s\n",
            "114:\tlearn: 0.0003245\ttotal: 6.07s\tremaining: 46.7s\n",
            "115:\tlearn: 0.0003240\ttotal: 6.11s\tremaining: 46.5s\n",
            "116:\tlearn: 0.0003236\ttotal: 6.14s\tremaining: 46.4s\n",
            "117:\tlearn: 0.0003156\ttotal: 6.18s\tremaining: 46.2s\n",
            "118:\tlearn: 0.0003152\ttotal: 6.24s\tremaining: 46.2s\n",
            "119:\tlearn: 0.0003051\ttotal: 6.28s\tremaining: 46.1s\n",
            "120:\tlearn: 0.0003048\ttotal: 6.33s\tremaining: 46s\n",
            "121:\tlearn: 0.0002976\ttotal: 6.36s\tremaining: 45.8s\n",
            "122:\tlearn: 0.0002884\ttotal: 6.4s\tremaining: 45.7s\n",
            "123:\tlearn: 0.0002881\ttotal: 6.44s\tremaining: 45.5s\n",
            "124:\tlearn: 0.0002880\ttotal: 6.48s\tremaining: 45.4s\n",
            "125:\tlearn: 0.0002878\ttotal: 6.52s\tremaining: 45.2s\n",
            "126:\tlearn: 0.0002791\ttotal: 6.56s\tremaining: 45.1s\n",
            "127:\tlearn: 0.0002730\ttotal: 6.59s\tremaining: 44.9s\n",
            "128:\tlearn: 0.0002728\ttotal: 6.62s\tremaining: 44.7s\n",
            "129:\tlearn: 0.0002727\ttotal: 6.66s\tremaining: 44.6s\n",
            "130:\tlearn: 0.0002726\ttotal: 6.69s\tremaining: 44.4s\n",
            "131:\tlearn: 0.0002646\ttotal: 6.73s\tremaining: 44.3s\n",
            "132:\tlearn: 0.0002645\ttotal: 6.77s\tremaining: 44.1s\n",
            "133:\tlearn: 0.0002570\ttotal: 6.81s\tremaining: 44s\n",
            "134:\tlearn: 0.0002498\ttotal: 6.85s\tremaining: 43.9s\n",
            "135:\tlearn: 0.0002498\ttotal: 6.88s\tremaining: 43.7s\n",
            "136:\tlearn: 0.0002497\ttotal: 6.91s\tremaining: 43.5s\n",
            "137:\tlearn: 0.0002496\ttotal: 6.95s\tremaining: 43.4s\n",
            "138:\tlearn: 0.0002483\ttotal: 6.99s\tremaining: 43.3s\n",
            "139:\tlearn: 0.0002482\ttotal: 7.06s\tremaining: 43.4s\n",
            "140:\tlearn: 0.0002433\ttotal: 7.1s\tremaining: 43.2s\n",
            "141:\tlearn: 0.0002388\ttotal: 7.17s\tremaining: 43.3s\n",
            "142:\tlearn: 0.0002387\ttotal: 7.21s\tremaining: 43.2s\n",
            "143:\tlearn: 0.0002386\ttotal: 7.25s\tremaining: 43.1s\n",
            "144:\tlearn: 0.0002361\ttotal: 7.29s\tremaining: 43s\n",
            "145:\tlearn: 0.0002360\ttotal: 7.33s\tremaining: 42.9s\n",
            "146:\tlearn: 0.0002360\ttotal: 7.35s\tremaining: 42.7s\n",
            "147:\tlearn: 0.0002347\ttotal: 7.37s\tremaining: 42.4s\n",
            "148:\tlearn: 0.0002305\ttotal: 7.41s\tremaining: 42.3s\n",
            "149:\tlearn: 0.0002295\ttotal: 7.45s\tremaining: 42.2s\n",
            "150:\tlearn: 0.0002271\ttotal: 7.47s\tremaining: 42s\n",
            "151:\tlearn: 0.0002271\ttotal: 7.51s\tremaining: 41.9s\n",
            "152:\tlearn: 0.0002248\ttotal: 7.54s\tremaining: 41.7s\n",
            "153:\tlearn: 0.0002209\ttotal: 7.56s\tremaining: 41.5s\n",
            "154:\tlearn: 0.0002209\ttotal: 7.62s\tremaining: 41.5s\n",
            "155:\tlearn: 0.0002209\ttotal: 7.66s\tremaining: 41.4s\n",
            "156:\tlearn: 0.0002208\ttotal: 7.72s\tremaining: 41.4s\n",
            "157:\tlearn: 0.0002208\ttotal: 7.77s\tremaining: 41.4s\n",
            "158:\tlearn: 0.0002207\ttotal: 7.84s\tremaining: 41.5s\n",
            "159:\tlearn: 0.0002207\ttotal: 7.89s\tremaining: 41.4s\n",
            "160:\tlearn: 0.0002207\ttotal: 7.93s\tremaining: 41.3s\n",
            "161:\tlearn: 0.0002206\ttotal: 7.95s\tremaining: 41.1s\n",
            "162:\tlearn: 0.0002206\ttotal: 8s\tremaining: 41.1s\n",
            "163:\tlearn: 0.0002206\ttotal: 8.03s\tremaining: 40.9s\n",
            "164:\tlearn: 0.0002206\ttotal: 8.06s\tremaining: 40.8s\n",
            "165:\tlearn: 0.0002205\ttotal: 8.09s\tremaining: 40.6s\n",
            "166:\tlearn: 0.0002205\ttotal: 8.12s\tremaining: 40.5s\n",
            "167:\tlearn: 0.0002205\ttotal: 8.16s\tremaining: 40.4s\n",
            "168:\tlearn: 0.0002204\ttotal: 8.18s\tremaining: 40.2s\n",
            "169:\tlearn: 0.0002204\ttotal: 8.22s\tremaining: 40.1s\n",
            "170:\tlearn: 0.0002204\ttotal: 8.24s\tremaining: 40s\n",
            "171:\tlearn: 0.0002204\ttotal: 8.28s\tremaining: 39.9s\n",
            "172:\tlearn: 0.0002203\ttotal: 8.31s\tremaining: 39.7s\n",
            "173:\tlearn: 0.0002203\ttotal: 8.34s\tremaining: 39.6s\n",
            "174:\tlearn: 0.0002165\ttotal: 8.37s\tremaining: 39.5s\n",
            "175:\tlearn: 0.0002165\ttotal: 8.41s\tremaining: 39.4s\n",
            "176:\tlearn: 0.0002112\ttotal: 8.44s\tremaining: 39.3s\n",
            "177:\tlearn: 0.0002112\ttotal: 8.47s\tremaining: 39.1s\n",
            "178:\tlearn: 0.0002111\ttotal: 8.51s\tremaining: 39s\n",
            "179:\tlearn: 0.0002078\ttotal: 8.58s\tremaining: 39.1s\n",
            "180:\tlearn: 0.0002077\ttotal: 8.63s\tremaining: 39.1s\n",
            "181:\tlearn: 0.0002077\ttotal: 8.68s\tremaining: 39s\n",
            "182:\tlearn: 0.0002059\ttotal: 8.73s\tremaining: 39s\n",
            "183:\tlearn: 0.0002058\ttotal: 8.79s\tremaining: 39s\n",
            "184:\tlearn: 0.0002058\ttotal: 8.83s\tremaining: 38.9s\n",
            "185:\tlearn: 0.0002009\ttotal: 8.87s\tremaining: 38.8s\n",
            "186:\tlearn: 0.0002009\ttotal: 8.9s\tremaining: 38.7s\n",
            "187:\tlearn: 0.0002009\ttotal: 8.93s\tremaining: 38.6s\n",
            "188:\tlearn: 0.0002009\ttotal: 8.97s\tremaining: 38.5s\n",
            "189:\tlearn: 0.0001991\ttotal: 9s\tremaining: 38.4s\n",
            "190:\tlearn: 0.0001974\ttotal: 9.03s\tremaining: 38.2s\n",
            "191:\tlearn: 0.0001974\ttotal: 9.06s\tremaining: 38.1s\n",
            "192:\tlearn: 0.0001974\ttotal: 9.1s\tremaining: 38s\n",
            "193:\tlearn: 0.0001929\ttotal: 9.13s\tremaining: 38s\n",
            "194:\tlearn: 0.0001928\ttotal: 9.17s\tremaining: 37.9s\n",
            "195:\tlearn: 0.0001928\ttotal: 9.21s\tremaining: 37.8s\n",
            "196:\tlearn: 0.0001928\ttotal: 9.25s\tremaining: 37.7s\n",
            "197:\tlearn: 0.0001928\ttotal: 9.28s\tremaining: 37.6s\n",
            "198:\tlearn: 0.0001900\ttotal: 9.31s\tremaining: 37.5s\n",
            "199:\tlearn: 0.0001900\ttotal: 9.36s\tremaining: 37.4s\n",
            "200:\tlearn: 0.0001885\ttotal: 9.39s\tremaining: 37.3s\n",
            "201:\tlearn: 0.0001885\ttotal: 9.43s\tremaining: 37.3s\n",
            "202:\tlearn: 0.0001884\ttotal: 9.48s\tremaining: 37.2s\n",
            "203:\tlearn: 0.0001842\ttotal: 9.54s\tremaining: 37.2s\n",
            "204:\tlearn: 0.0001842\ttotal: 9.6s\tremaining: 37.2s\n",
            "205:\tlearn: 0.0001842\ttotal: 9.68s\tremaining: 37.3s\n",
            "206:\tlearn: 0.0001841\ttotal: 9.74s\tremaining: 37.3s\n",
            "207:\tlearn: 0.0001841\ttotal: 9.78s\tremaining: 37.2s\n",
            "208:\tlearn: 0.0001841\ttotal: 9.81s\tremaining: 37.1s\n",
            "209:\tlearn: 0.0001801\ttotal: 9.85s\tremaining: 37.1s\n",
            "210:\tlearn: 0.0001801\ttotal: 9.87s\tremaining: 36.9s\n",
            "211:\tlearn: 0.0001787\ttotal: 9.91s\tremaining: 36.8s\n",
            "212:\tlearn: 0.0001787\ttotal: 9.95s\tremaining: 36.8s\n",
            "213:\tlearn: 0.0001787\ttotal: 9.98s\tremaining: 36.7s\n",
            "214:\tlearn: 0.0001774\ttotal: 10s\tremaining: 36.6s\n",
            "215:\tlearn: 0.0001774\ttotal: 10s\tremaining: 36.4s\n",
            "216:\tlearn: 0.0001773\ttotal: 10.1s\tremaining: 36.3s\n",
            "217:\tlearn: 0.0001773\ttotal: 10.1s\tremaining: 36.3s\n",
            "218:\tlearn: 0.0001773\ttotal: 10.2s\tremaining: 36.2s\n",
            "219:\tlearn: 0.0001773\ttotal: 10.2s\tremaining: 36.1s\n",
            "220:\tlearn: 0.0001760\ttotal: 10.2s\tremaining: 36s\n",
            "221:\tlearn: 0.0001760\ttotal: 10.3s\tremaining: 35.9s\n",
            "222:\tlearn: 0.0001760\ttotal: 10.3s\tremaining: 35.8s\n",
            "223:\tlearn: 0.0001760\ttotal: 10.3s\tremaining: 35.7s\n",
            "224:\tlearn: 0.0001759\ttotal: 10.4s\tremaining: 35.7s\n",
            "225:\tlearn: 0.0001759\ttotal: 10.4s\tremaining: 35.6s\n",
            "226:\tlearn: 0.0001759\ttotal: 10.5s\tremaining: 35.6s\n",
            "227:\tlearn: 0.0001759\ttotal: 10.5s\tremaining: 35.5s\n",
            "228:\tlearn: 0.0001758\ttotal: 10.5s\tremaining: 35.5s\n",
            "229:\tlearn: 0.0001735\ttotal: 10.6s\tremaining: 35.4s\n",
            "230:\tlearn: 0.0001730\ttotal: 10.6s\tremaining: 35.4s\n",
            "231:\tlearn: 0.0001718\ttotal: 10.7s\tremaining: 35.3s\n",
            "232:\tlearn: 0.0001718\ttotal: 10.7s\tremaining: 35.2s\n",
            "233:\tlearn: 0.0001718\ttotal: 10.7s\tremaining: 35.1s\n",
            "234:\tlearn: 0.0001717\ttotal: 10.8s\tremaining: 35.1s\n",
            "235:\tlearn: 0.0001712\ttotal: 10.8s\tremaining: 35s\n",
            "236:\tlearn: 0.0001712\ttotal: 10.8s\tremaining: 34.9s\n",
            "237:\tlearn: 0.0001677\ttotal: 10.9s\tremaining: 34.8s\n",
            "238:\tlearn: 0.0001671\ttotal: 10.9s\tremaining: 34.7s\n",
            "239:\tlearn: 0.0001671\ttotal: 10.9s\tremaining: 34.6s\n",
            "240:\tlearn: 0.0001671\ttotal: 11s\tremaining: 34.5s\n",
            "241:\tlearn: 0.0001650\ttotal: 11s\tremaining: 34.4s\n",
            "242:\tlearn: 0.0001639\ttotal: 11s\tremaining: 34.4s\n",
            "243:\tlearn: 0.0001639\ttotal: 11.1s\tremaining: 34.3s\n",
            "244:\tlearn: 0.0001639\ttotal: 11.1s\tremaining: 34.2s\n",
            "245:\tlearn: 0.0001629\ttotal: 11.1s\tremaining: 34.1s\n",
            "246:\tlearn: 0.0001619\ttotal: 11.2s\tremaining: 34s\n",
            "247:\tlearn: 0.0001614\ttotal: 11.2s\tremaining: 33.9s\n",
            "248:\tlearn: 0.0001614\ttotal: 11.2s\tremaining: 33.9s\n",
            "249:\tlearn: 0.0001614\ttotal: 11.3s\tremaining: 33.8s\n",
            "250:\tlearn: 0.0001594\ttotal: 11.3s\tremaining: 33.7s\n",
            "251:\tlearn: 0.0001594\ttotal: 11.3s\tremaining: 33.6s\n",
            "252:\tlearn: 0.0001594\ttotal: 11.4s\tremaining: 33.5s\n",
            "253:\tlearn: 0.0001584\ttotal: 11.4s\tremaining: 33.4s\n",
            "254:\tlearn: 0.0001584\ttotal: 11.4s\tremaining: 33.4s\n",
            "255:\tlearn: 0.0001584\ttotal: 11.5s\tremaining: 33.3s\n",
            "256:\tlearn: 0.0001584\ttotal: 11.5s\tremaining: 33.3s\n",
            "257:\tlearn: 0.0001584\ttotal: 11.5s\tremaining: 33.2s\n",
            "258:\tlearn: 0.0001583\ttotal: 11.6s\tremaining: 33.1s\n",
            "259:\tlearn: 0.0001583\ttotal: 11.6s\tremaining: 33.1s\n",
            "260:\tlearn: 0.0001583\ttotal: 11.7s\tremaining: 33s\n",
            "261:\tlearn: 0.0001574\ttotal: 11.7s\tremaining: 32.9s\n",
            "262:\tlearn: 0.0001573\ttotal: 11.7s\tremaining: 32.8s\n",
            "263:\tlearn: 0.0001573\ttotal: 11.8s\tremaining: 32.8s\n",
            "264:\tlearn: 0.0001573\ttotal: 11.8s\tremaining: 32.7s\n",
            "265:\tlearn: 0.0001573\ttotal: 11.8s\tremaining: 32.6s\n",
            "266:\tlearn: 0.0001569\ttotal: 11.9s\tremaining: 32.6s\n",
            "267:\tlearn: 0.0001569\ttotal: 11.9s\tremaining: 32.5s\n",
            "268:\tlearn: 0.0001569\ttotal: 12s\tremaining: 32.5s\n",
            "269:\tlearn: 0.0001569\ttotal: 12s\tremaining: 32.4s\n",
            "270:\tlearn: 0.0001568\ttotal: 12s\tremaining: 32.4s\n",
            "271:\tlearn: 0.0001568\ttotal: 12.1s\tremaining: 32.3s\n",
            "272:\tlearn: 0.0001568\ttotal: 12.1s\tremaining: 32.2s\n",
            "273:\tlearn: 0.0001568\ttotal: 12.1s\tremaining: 32.1s\n",
            "274:\tlearn: 0.0001568\ttotal: 12.2s\tremaining: 32.1s\n",
            "275:\tlearn: 0.0001568\ttotal: 12.2s\tremaining: 32s\n",
            "276:\tlearn: 0.0001559\ttotal: 12.2s\tremaining: 31.9s\n",
            "277:\tlearn: 0.0001555\ttotal: 12.3s\tremaining: 31.9s\n",
            "278:\tlearn: 0.0001555\ttotal: 12.3s\tremaining: 31.8s\n",
            "279:\tlearn: 0.0001555\ttotal: 12.3s\tremaining: 31.7s\n",
            "280:\tlearn: 0.0001554\ttotal: 12.4s\tremaining: 31.7s\n",
            "281:\tlearn: 0.0001546\ttotal: 12.4s\tremaining: 31.6s\n",
            "282:\tlearn: 0.0001537\ttotal: 12.4s\tremaining: 31.5s\n",
            "283:\tlearn: 0.0001537\ttotal: 12.5s\tremaining: 31.5s\n",
            "284:\tlearn: 0.0001520\ttotal: 12.5s\tremaining: 31.4s\n",
            "285:\tlearn: 0.0001502\ttotal: 12.5s\tremaining: 31.3s\n",
            "286:\tlearn: 0.0001502\ttotal: 12.6s\tremaining: 31.3s\n",
            "287:\tlearn: 0.0001499\ttotal: 12.6s\tremaining: 31.2s\n",
            "288:\tlearn: 0.0001483\ttotal: 12.7s\tremaining: 31.2s\n",
            "289:\tlearn: 0.0001482\ttotal: 12.7s\tremaining: 31.1s\n",
            "290:\tlearn: 0.0001482\ttotal: 12.7s\tremaining: 31s\n",
            "291:\tlearn: 0.0001482\ttotal: 12.8s\tremaining: 31s\n",
            "292:\tlearn: 0.0001482\ttotal: 12.8s\tremaining: 30.9s\n",
            "293:\tlearn: 0.0001482\ttotal: 12.9s\tremaining: 30.9s\n",
            "294:\tlearn: 0.0001482\ttotal: 12.9s\tremaining: 30.8s\n",
            "295:\tlearn: 0.0001482\ttotal: 12.9s\tremaining: 30.7s\n",
            "296:\tlearn: 0.0001481\ttotal: 12.9s\tremaining: 30.6s\n",
            "297:\tlearn: 0.0001481\ttotal: 13s\tremaining: 30.6s\n",
            "298:\tlearn: 0.0001465\ttotal: 13s\tremaining: 30.5s\n",
            "299:\tlearn: 0.0001465\ttotal: 13s\tremaining: 30.4s\n",
            "300:\tlearn: 0.0001465\ttotal: 13.1s\tremaining: 30.4s\n",
            "301:\tlearn: 0.0001465\ttotal: 13.1s\tremaining: 30.3s\n",
            "302:\tlearn: 0.0001465\ttotal: 13.1s\tremaining: 30.2s\n",
            "303:\tlearn: 0.0001465\ttotal: 13.2s\tremaining: 30.2s\n",
            "304:\tlearn: 0.0001457\ttotal: 13.2s\tremaining: 30.1s\n",
            "305:\tlearn: 0.0001457\ttotal: 13.3s\tremaining: 30.1s\n",
            "306:\tlearn: 0.0001457\ttotal: 13.3s\tremaining: 30s\n",
            "307:\tlearn: 0.0001457\ttotal: 13.3s\tremaining: 30s\n",
            "308:\tlearn: 0.0001457\ttotal: 13.4s\tremaining: 29.9s\n",
            "309:\tlearn: 0.0001457\ttotal: 13.4s\tremaining: 29.8s\n",
            "310:\tlearn: 0.0001456\ttotal: 13.4s\tremaining: 29.8s\n",
            "311:\tlearn: 0.0001456\ttotal: 13.5s\tremaining: 29.7s\n",
            "312:\tlearn: 0.0001456\ttotal: 13.5s\tremaining: 29.7s\n",
            "313:\tlearn: 0.0001456\ttotal: 13.6s\tremaining: 29.6s\n",
            "314:\tlearn: 0.0001456\ttotal: 13.6s\tremaining: 29.5s\n",
            "315:\tlearn: 0.0001456\ttotal: 13.6s\tremaining: 29.5s\n",
            "316:\tlearn: 0.0001456\ttotal: 13.7s\tremaining: 29.4s\n",
            "317:\tlearn: 0.0001455\ttotal: 13.7s\tremaining: 29.4s\n",
            "318:\tlearn: 0.0001440\ttotal: 13.7s\tremaining: 29.3s\n",
            "319:\tlearn: 0.0001440\ttotal: 13.8s\tremaining: 29.2s\n",
            "320:\tlearn: 0.0001440\ttotal: 13.8s\tremaining: 29.2s\n",
            "321:\tlearn: 0.0001412\ttotal: 13.8s\tremaining: 29.1s\n",
            "322:\tlearn: 0.0001412\ttotal: 13.9s\tremaining: 29.1s\n",
            "323:\tlearn: 0.0001412\ttotal: 13.9s\tremaining: 29s\n",
            "324:\tlearn: 0.0001412\ttotal: 14s\tremaining: 29s\n",
            "325:\tlearn: 0.0001412\ttotal: 14s\tremaining: 28.9s\n",
            "326:\tlearn: 0.0001412\ttotal: 14s\tremaining: 28.9s\n",
            "327:\tlearn: 0.0001412\ttotal: 14.1s\tremaining: 28.8s\n",
            "328:\tlearn: 0.0001397\ttotal: 14.1s\tremaining: 28.8s\n",
            "329:\tlearn: 0.0001397\ttotal: 14.1s\tremaining: 28.7s\n",
            "330:\tlearn: 0.0001397\ttotal: 14.2s\tremaining: 28.6s\n",
            "331:\tlearn: 0.0001397\ttotal: 14.2s\tremaining: 28.6s\n",
            "332:\tlearn: 0.0001396\ttotal: 14.2s\tremaining: 28.5s\n",
            "333:\tlearn: 0.0001390\ttotal: 14.3s\tremaining: 28.4s\n",
            "334:\tlearn: 0.0001383\ttotal: 14.3s\tremaining: 28.4s\n",
            "335:\tlearn: 0.0001383\ttotal: 14.5s\tremaining: 28.6s\n",
            "336:\tlearn: 0.0001383\ttotal: 14.5s\tremaining: 28.5s\n",
            "337:\tlearn: 0.0001383\ttotal: 14.5s\tremaining: 28.5s\n",
            "338:\tlearn: 0.0001383\ttotal: 14.6s\tremaining: 28.4s\n",
            "339:\tlearn: 0.0001383\ttotal: 14.6s\tremaining: 28.4s\n",
            "340:\tlearn: 0.0001382\ttotal: 14.7s\tremaining: 28.3s\n",
            "341:\tlearn: 0.0001369\ttotal: 14.7s\tremaining: 28.3s\n",
            "342:\tlearn: 0.0001369\ttotal: 14.8s\tremaining: 28.3s\n",
            "343:\tlearn: 0.0001369\ttotal: 14.8s\tremaining: 28.2s\n",
            "344:\tlearn: 0.0001368\ttotal: 14.8s\tremaining: 28.2s\n",
            "345:\tlearn: 0.0001366\ttotal: 14.9s\tremaining: 28.1s\n",
            "346:\tlearn: 0.0001366\ttotal: 14.9s\tremaining: 28.1s\n",
            "347:\tlearn: 0.0001365\ttotal: 15s\tremaining: 28s\n",
            "348:\tlearn: 0.0001365\ttotal: 15s\tremaining: 28s\n",
            "349:\tlearn: 0.0001365\ttotal: 15s\tremaining: 27.9s\n",
            "350:\tlearn: 0.0001363\ttotal: 15.1s\tremaining: 27.9s\n",
            "351:\tlearn: 0.0001363\ttotal: 15.1s\tremaining: 27.8s\n",
            "352:\tlearn: 0.0001363\ttotal: 15.2s\tremaining: 27.8s\n",
            "353:\tlearn: 0.0001363\ttotal: 15.2s\tremaining: 27.7s\n",
            "354:\tlearn: 0.0001357\ttotal: 15.2s\tremaining: 27.6s\n",
            "355:\tlearn: 0.0001357\ttotal: 15.2s\tremaining: 27.6s\n",
            "356:\tlearn: 0.0001357\ttotal: 15.3s\tremaining: 27.5s\n",
            "357:\tlearn: 0.0001356\ttotal: 15.3s\tremaining: 27.4s\n",
            "358:\tlearn: 0.0001356\ttotal: 15.3s\tremaining: 27.4s\n",
            "359:\tlearn: 0.0001356\ttotal: 15.4s\tremaining: 27.3s\n",
            "360:\tlearn: 0.0001356\ttotal: 15.4s\tremaining: 27.3s\n",
            "361:\tlearn: 0.0001353\ttotal: 15.4s\tremaining: 27.2s\n",
            "362:\tlearn: 0.0001353\ttotal: 15.5s\tremaining: 27.2s\n",
            "363:\tlearn: 0.0001353\ttotal: 15.5s\tremaining: 27.1s\n",
            "364:\tlearn: 0.0001353\ttotal: 15.6s\tremaining: 27.1s\n",
            "365:\tlearn: 0.0001353\ttotal: 15.6s\tremaining: 27s\n",
            "366:\tlearn: 0.0001353\ttotal: 15.6s\tremaining: 27s\n",
            "367:\tlearn: 0.0001353\ttotal: 15.7s\tremaining: 26.9s\n",
            "368:\tlearn: 0.0001352\ttotal: 15.7s\tremaining: 26.9s\n",
            "369:\tlearn: 0.0001352\ttotal: 15.7s\tremaining: 26.8s\n",
            "370:\tlearn: 0.0001352\ttotal: 15.8s\tremaining: 26.7s\n",
            "371:\tlearn: 0.0001352\ttotal: 15.8s\tremaining: 26.7s\n",
            "372:\tlearn: 0.0001352\ttotal: 15.8s\tremaining: 26.6s\n",
            "373:\tlearn: 0.0001346\ttotal: 15.9s\tremaining: 26.6s\n",
            "374:\tlearn: 0.0001323\ttotal: 15.9s\tremaining: 26.5s\n",
            "375:\tlearn: 0.0001322\ttotal: 15.9s\tremaining: 26.5s\n",
            "376:\tlearn: 0.0001299\ttotal: 16s\tremaining: 26.4s\n",
            "377:\tlearn: 0.0001299\ttotal: 16s\tremaining: 26.4s\n",
            "378:\tlearn: 0.0001299\ttotal: 16.1s\tremaining: 26.3s\n",
            "379:\tlearn: 0.0001299\ttotal: 16.1s\tremaining: 26.3s\n",
            "380:\tlearn: 0.0001296\ttotal: 16.2s\tremaining: 26.2s\n",
            "381:\tlearn: 0.0001296\ttotal: 16.2s\tremaining: 26.2s\n",
            "382:\tlearn: 0.0001296\ttotal: 16.2s\tremaining: 26.1s\n",
            "383:\tlearn: 0.0001296\ttotal: 16.3s\tremaining: 26.1s\n",
            "384:\tlearn: 0.0001291\ttotal: 16.3s\tremaining: 26.1s\n",
            "385:\tlearn: 0.0001290\ttotal: 16.3s\tremaining: 26s\n",
            "386:\tlearn: 0.0001290\ttotal: 16.4s\tremaining: 25.9s\n",
            "387:\tlearn: 0.0001290\ttotal: 16.4s\tremaining: 25.9s\n",
            "388:\tlearn: 0.0001290\ttotal: 16.4s\tremaining: 25.8s\n",
            "389:\tlearn: 0.0001290\ttotal: 16.5s\tremaining: 25.7s\n",
            "390:\tlearn: 0.0001279\ttotal: 16.5s\tremaining: 25.7s\n",
            "391:\tlearn: 0.0001279\ttotal: 16.5s\tremaining: 25.7s\n",
            "392:\tlearn: 0.0001279\ttotal: 16.6s\tremaining: 25.6s\n",
            "393:\tlearn: 0.0001279\ttotal: 16.6s\tremaining: 25.6s\n",
            "394:\tlearn: 0.0001273\ttotal: 16.7s\tremaining: 25.5s\n",
            "395:\tlearn: 0.0001273\ttotal: 16.7s\tremaining: 25.5s\n",
            "396:\tlearn: 0.0001251\ttotal: 16.7s\tremaining: 25.4s\n",
            "397:\tlearn: 0.0001251\ttotal: 16.8s\tremaining: 25.4s\n",
            "398:\tlearn: 0.0001251\ttotal: 16.8s\tremaining: 25.3s\n",
            "399:\tlearn: 0.0001251\ttotal: 16.8s\tremaining: 25.2s\n",
            "400:\tlearn: 0.0001251\ttotal: 16.8s\tremaining: 25.2s\n",
            "401:\tlearn: 0.0001251\ttotal: 16.9s\tremaining: 25.1s\n",
            "402:\tlearn: 0.0001251\ttotal: 16.9s\tremaining: 25s\n",
            "403:\tlearn: 0.0001250\ttotal: 16.9s\tremaining: 25s\n",
            "404:\tlearn: 0.0001245\ttotal: 17s\tremaining: 25s\n",
            "405:\tlearn: 0.0001244\ttotal: 17s\tremaining: 24.9s\n",
            "406:\tlearn: 0.0001244\ttotal: 17.1s\tremaining: 24.9s\n",
            "407:\tlearn: 0.0001244\ttotal: 17.1s\tremaining: 24.8s\n",
            "408:\tlearn: 0.0001244\ttotal: 17.1s\tremaining: 24.7s\n",
            "409:\tlearn: 0.0001244\ttotal: 17.2s\tremaining: 24.7s\n",
            "410:\tlearn: 0.0001243\ttotal: 17.2s\tremaining: 24.7s\n",
            "411:\tlearn: 0.0001243\ttotal: 17.2s\tremaining: 24.6s\n",
            "412:\tlearn: 0.0001241\ttotal: 17.3s\tremaining: 24.6s\n",
            "413:\tlearn: 0.0001221\ttotal: 17.3s\tremaining: 24.5s\n",
            "414:\tlearn: 0.0001219\ttotal: 17.4s\tremaining: 24.5s\n",
            "415:\tlearn: 0.0001219\ttotal: 17.4s\tremaining: 24.4s\n",
            "416:\tlearn: 0.0001219\ttotal: 17.4s\tremaining: 24.4s\n",
            "417:\tlearn: 0.0001219\ttotal: 17.5s\tremaining: 24.3s\n",
            "418:\tlearn: 0.0001218\ttotal: 17.5s\tremaining: 24.3s\n",
            "419:\tlearn: 0.0001214\ttotal: 17.5s\tremaining: 24.2s\n",
            "420:\tlearn: 0.0001214\ttotal: 17.6s\tremaining: 24.2s\n",
            "421:\tlearn: 0.0001214\ttotal: 17.6s\tremaining: 24.1s\n",
            "422:\tlearn: 0.0001213\ttotal: 17.6s\tremaining: 24.1s\n",
            "423:\tlearn: 0.0001213\ttotal: 17.7s\tremaining: 24s\n",
            "424:\tlearn: 0.0001209\ttotal: 17.7s\tremaining: 23.9s\n",
            "425:\tlearn: 0.0001188\ttotal: 17.7s\tremaining: 23.9s\n",
            "426:\tlearn: 0.0001188\ttotal: 17.8s\tremaining: 23.9s\n",
            "427:\tlearn: 0.0001188\ttotal: 17.8s\tremaining: 23.8s\n",
            "428:\tlearn: 0.0001188\ttotal: 17.9s\tremaining: 23.8s\n",
            "429:\tlearn: 0.0001168\ttotal: 17.9s\tremaining: 23.7s\n",
            "430:\tlearn: 0.0001168\ttotal: 17.9s\tremaining: 23.7s\n",
            "431:\tlearn: 0.0001159\ttotal: 18s\tremaining: 23.6s\n",
            "432:\tlearn: 0.0001158\ttotal: 18s\tremaining: 23.6s\n",
            "433:\tlearn: 0.0001158\ttotal: 18.1s\tremaining: 23.6s\n",
            "434:\tlearn: 0.0001158\ttotal: 18.1s\tremaining: 23.5s\n",
            "435:\tlearn: 0.0001158\ttotal: 18.1s\tremaining: 23.5s\n",
            "436:\tlearn: 0.0001156\ttotal: 18.2s\tremaining: 23.4s\n",
            "437:\tlearn: 0.0001156\ttotal: 18.2s\tremaining: 23.4s\n",
            "438:\tlearn: 0.0001156\ttotal: 18.3s\tremaining: 23.3s\n",
            "439:\tlearn: 0.0001156\ttotal: 18.3s\tremaining: 23.3s\n",
            "440:\tlearn: 0.0001146\ttotal: 18.3s\tremaining: 23.3s\n",
            "441:\tlearn: 0.0001146\ttotal: 18.4s\tremaining: 23.2s\n",
            "442:\tlearn: 0.0001146\ttotal: 18.4s\tremaining: 23.1s\n",
            "443:\tlearn: 0.0001144\ttotal: 18.4s\tremaining: 23.1s\n",
            "444:\tlearn: 0.0001144\ttotal: 18.5s\tremaining: 23s\n",
            "445:\tlearn: 0.0001144\ttotal: 18.5s\tremaining: 23s\n",
            "446:\tlearn: 0.0001144\ttotal: 18.5s\tremaining: 22.9s\n",
            "447:\tlearn: 0.0001144\ttotal: 18.6s\tremaining: 22.9s\n",
            "448:\tlearn: 0.0001144\ttotal: 18.6s\tremaining: 22.8s\n",
            "449:\tlearn: 0.0001144\ttotal: 18.6s\tremaining: 22.8s\n",
            "450:\tlearn: 0.0001144\ttotal: 18.7s\tremaining: 22.7s\n",
            "451:\tlearn: 0.0001143\ttotal: 18.7s\tremaining: 22.7s\n",
            "452:\tlearn: 0.0001143\ttotal: 18.8s\tremaining: 22.7s\n",
            "453:\tlearn: 0.0001143\ttotal: 18.8s\tremaining: 22.6s\n",
            "454:\tlearn: 0.0001142\ttotal: 18.8s\tremaining: 22.6s\n",
            "455:\tlearn: 0.0001124\ttotal: 18.9s\tremaining: 22.6s\n",
            "456:\tlearn: 0.0001120\ttotal: 19s\tremaining: 22.5s\n",
            "457:\tlearn: 0.0001120\ttotal: 19s\tremaining: 22.5s\n",
            "458:\tlearn: 0.0001120\ttotal: 19s\tremaining: 22.4s\n",
            "459:\tlearn: 0.0001120\ttotal: 19.1s\tremaining: 22.4s\n",
            "460:\tlearn: 0.0001118\ttotal: 19.1s\tremaining: 22.3s\n",
            "461:\tlearn: 0.0001118\ttotal: 19.2s\tremaining: 22.3s\n",
            "462:\tlearn: 0.0001118\ttotal: 19.2s\tremaining: 22.3s\n",
            "463:\tlearn: 0.0001101\ttotal: 19.2s\tremaining: 22.2s\n",
            "464:\tlearn: 0.0001101\ttotal: 19.3s\tremaining: 22.2s\n",
            "465:\tlearn: 0.0001101\ttotal: 19.3s\tremaining: 22.1s\n",
            "466:\tlearn: 0.0001101\ttotal: 19.4s\tremaining: 22.1s\n",
            "467:\tlearn: 0.0001086\ttotal: 19.4s\tremaining: 22s\n",
            "468:\tlearn: 0.0001086\ttotal: 19.4s\tremaining: 22s\n",
            "469:\tlearn: 0.0001085\ttotal: 19.5s\tremaining: 22s\n",
            "470:\tlearn: 0.0001085\ttotal: 19.5s\tremaining: 21.9s\n",
            "471:\tlearn: 0.0001085\ttotal: 19.5s\tremaining: 21.9s\n",
            "472:\tlearn: 0.0001085\ttotal: 19.6s\tremaining: 21.8s\n",
            "473:\tlearn: 0.0001084\ttotal: 19.6s\tremaining: 21.8s\n",
            "474:\tlearn: 0.0001083\ttotal: 19.7s\tremaining: 21.7s\n",
            "475:\tlearn: 0.0001083\ttotal: 19.7s\tremaining: 21.7s\n",
            "476:\tlearn: 0.0001083\ttotal: 19.7s\tremaining: 21.6s\n",
            "477:\tlearn: 0.0001083\ttotal: 19.8s\tremaining: 21.6s\n",
            "478:\tlearn: 0.0001083\ttotal: 19.8s\tremaining: 21.6s\n",
            "479:\tlearn: 0.0001083\ttotal: 19.9s\tremaining: 21.5s\n",
            "480:\tlearn: 0.0001083\ttotal: 19.9s\tremaining: 21.5s\n",
            "481:\tlearn: 0.0001083\ttotal: 19.9s\tremaining: 21.4s\n",
            "482:\tlearn: 0.0001083\ttotal: 19.9s\tremaining: 21.3s\n",
            "483:\tlearn: 0.0001083\ttotal: 20s\tremaining: 21.3s\n",
            "484:\tlearn: 0.0001082\ttotal: 20s\tremaining: 21.2s\n",
            "485:\tlearn: 0.0001079\ttotal: 20s\tremaining: 21.2s\n",
            "486:\tlearn: 0.0001079\ttotal: 20.1s\tremaining: 21.2s\n",
            "487:\tlearn: 0.0001079\ttotal: 20.1s\tremaining: 21.1s\n",
            "488:\tlearn: 0.0001079\ttotal: 20.2s\tremaining: 21.1s\n",
            "489:\tlearn: 0.0001075\ttotal: 20.2s\tremaining: 21s\n",
            "490:\tlearn: 0.0001075\ttotal: 20.2s\tremaining: 21s\n",
            "491:\tlearn: 0.0001075\ttotal: 20.2s\tremaining: 20.9s\n",
            "492:\tlearn: 0.0001075\ttotal: 20.3s\tremaining: 20.9s\n",
            "493:\tlearn: 0.0001062\ttotal: 20.3s\tremaining: 20.8s\n",
            "494:\tlearn: 0.0001060\ttotal: 20.4s\tremaining: 20.8s\n",
            "495:\tlearn: 0.0001060\ttotal: 20.4s\tremaining: 20.7s\n",
            "496:\tlearn: 0.0001060\ttotal: 20.4s\tremaining: 20.7s\n",
            "497:\tlearn: 0.0001060\ttotal: 20.5s\tremaining: 20.6s\n",
            "498:\tlearn: 0.0001060\ttotal: 20.5s\tremaining: 20.6s\n",
            "499:\tlearn: 0.0001060\ttotal: 20.5s\tremaining: 20.5s\n",
            "500:\tlearn: 0.0001060\ttotal: 20.6s\tremaining: 20.5s\n",
            "501:\tlearn: 0.0001059\ttotal: 20.6s\tremaining: 20.4s\n",
            "502:\tlearn: 0.0001059\ttotal: 20.6s\tremaining: 20.4s\n",
            "503:\tlearn: 0.0001059\ttotal: 20.7s\tremaining: 20.3s\n",
            "504:\tlearn: 0.0001059\ttotal: 20.7s\tremaining: 20.3s\n",
            "505:\tlearn: 0.0001059\ttotal: 20.8s\tremaining: 20.3s\n",
            "506:\tlearn: 0.0001059\ttotal: 20.8s\tremaining: 20.2s\n",
            "507:\tlearn: 0.0001059\ttotal: 20.8s\tremaining: 20.2s\n",
            "508:\tlearn: 0.0001055\ttotal: 20.8s\tremaining: 20.1s\n",
            "509:\tlearn: 0.0001054\ttotal: 20.9s\tremaining: 20s\n",
            "510:\tlearn: 0.0001045\ttotal: 20.9s\tremaining: 20s\n",
            "511:\tlearn: 0.0001045\ttotal: 20.9s\tremaining: 20s\n",
            "512:\tlearn: 0.0001045\ttotal: 21s\tremaining: 19.9s\n",
            "513:\tlearn: 0.0001045\ttotal: 21s\tremaining: 19.9s\n",
            "514:\tlearn: 0.0001045\ttotal: 21.1s\tremaining: 19.8s\n",
            "515:\tlearn: 0.0001045\ttotal: 21.1s\tremaining: 19.8s\n",
            "516:\tlearn: 0.0001045\ttotal: 21.1s\tremaining: 19.7s\n",
            "517:\tlearn: 0.0001045\ttotal: 21.2s\tremaining: 19.7s\n",
            "518:\tlearn: 0.0001045\ttotal: 21.2s\tremaining: 19.7s\n",
            "519:\tlearn: 0.0001045\ttotal: 21.2s\tremaining: 19.6s\n",
            "520:\tlearn: 0.0001044\ttotal: 21.3s\tremaining: 19.6s\n",
            "521:\tlearn: 0.0001044\ttotal: 21.3s\tremaining: 19.5s\n",
            "522:\tlearn: 0.0001044\ttotal: 21.3s\tremaining: 19.5s\n",
            "523:\tlearn: 0.0001044\ttotal: 21.4s\tremaining: 19.4s\n",
            "524:\tlearn: 0.0001044\ttotal: 21.4s\tremaining: 19.4s\n",
            "525:\tlearn: 0.0001044\ttotal: 21.4s\tremaining: 19.3s\n",
            "526:\tlearn: 0.0001044\ttotal: 21.5s\tremaining: 19.3s\n",
            "527:\tlearn: 0.0001044\ttotal: 21.5s\tremaining: 19.2s\n",
            "528:\tlearn: 0.0001044\ttotal: 21.6s\tremaining: 19.2s\n",
            "529:\tlearn: 0.0001044\ttotal: 21.6s\tremaining: 19.2s\n",
            "530:\tlearn: 0.0001044\ttotal: 21.6s\tremaining: 19.1s\n",
            "531:\tlearn: 0.0001036\ttotal: 21.7s\tremaining: 19.1s\n",
            "532:\tlearn: 0.0001036\ttotal: 21.7s\tremaining: 19s\n",
            "533:\tlearn: 0.0001036\ttotal: 21.8s\tremaining: 19s\n",
            "534:\tlearn: 0.0001036\ttotal: 21.8s\tremaining: 18.9s\n",
            "535:\tlearn: 0.0001035\ttotal: 21.8s\tremaining: 18.9s\n",
            "536:\tlearn: 0.0001034\ttotal: 21.9s\tremaining: 18.9s\n",
            "537:\tlearn: 0.0001034\ttotal: 21.9s\tremaining: 18.8s\n",
            "538:\tlearn: 0.0001033\ttotal: 21.9s\tremaining: 18.8s\n",
            "539:\tlearn: 0.0001033\ttotal: 22s\tremaining: 18.7s\n",
            "540:\tlearn: 0.0001032\ttotal: 22s\tremaining: 18.7s\n",
            "541:\tlearn: 0.0001032\ttotal: 22s\tremaining: 18.6s\n",
            "542:\tlearn: 0.0001032\ttotal: 22.1s\tremaining: 18.6s\n",
            "543:\tlearn: 0.0001032\ttotal: 22.1s\tremaining: 18.5s\n",
            "544:\tlearn: 0.0001032\ttotal: 22.1s\tremaining: 18.5s\n",
            "545:\tlearn: 0.0001032\ttotal: 22.2s\tremaining: 18.4s\n",
            "546:\tlearn: 0.0001031\ttotal: 22.2s\tremaining: 18.4s\n",
            "547:\tlearn: 0.0001031\ttotal: 22.2s\tremaining: 18.3s\n",
            "548:\tlearn: 0.0001029\ttotal: 22.3s\tremaining: 18.3s\n",
            "549:\tlearn: 0.0001017\ttotal: 22.3s\tremaining: 18.3s\n",
            "550:\tlearn: 0.0001017\ttotal: 22.4s\tremaining: 18.2s\n",
            "551:\tlearn: 0.0001017\ttotal: 22.4s\tremaining: 18.2s\n",
            "552:\tlearn: 0.0001009\ttotal: 22.4s\tremaining: 18.1s\n",
            "553:\tlearn: 0.0001006\ttotal: 22.5s\tremaining: 18.1s\n",
            "554:\tlearn: 0.0001006\ttotal: 22.5s\tremaining: 18s\n",
            "555:\tlearn: 0.0000992\ttotal: 22.5s\tremaining: 18s\n",
            "556:\tlearn: 0.0000992\ttotal: 22.6s\tremaining: 18s\n",
            "557:\tlearn: 0.0000992\ttotal: 22.6s\tremaining: 17.9s\n",
            "558:\tlearn: 0.0000992\ttotal: 22.6s\tremaining: 17.9s\n",
            "559:\tlearn: 0.0000992\ttotal: 22.7s\tremaining: 17.8s\n",
            "560:\tlearn: 0.0000991\ttotal: 22.7s\tremaining: 17.8s\n",
            "561:\tlearn: 0.0000990\ttotal: 22.8s\tremaining: 17.7s\n",
            "562:\tlearn: 0.0000990\ttotal: 22.8s\tremaining: 17.7s\n",
            "563:\tlearn: 0.0000987\ttotal: 22.8s\tremaining: 17.7s\n",
            "564:\tlearn: 0.0000987\ttotal: 22.9s\tremaining: 17.6s\n",
            "565:\tlearn: 0.0000984\ttotal: 22.9s\tremaining: 17.6s\n",
            "566:\tlearn: 0.0000984\ttotal: 22.9s\tremaining: 17.5s\n",
            "567:\tlearn: 0.0000984\ttotal: 23s\tremaining: 17.5s\n",
            "568:\tlearn: 0.0000984\ttotal: 23s\tremaining: 17.4s\n",
            "569:\tlearn: 0.0000984\ttotal: 23.1s\tremaining: 17.4s\n",
            "570:\tlearn: 0.0000984\ttotal: 23.2s\tremaining: 17.4s\n",
            "571:\tlearn: 0.0000984\ttotal: 23.3s\tremaining: 17.4s\n",
            "572:\tlearn: 0.0000984\ttotal: 23.4s\tremaining: 17.4s\n",
            "573:\tlearn: 0.0000984\ttotal: 23.4s\tremaining: 17.4s\n",
            "574:\tlearn: 0.0000984\ttotal: 23.5s\tremaining: 17.3s\n",
            "575:\tlearn: 0.0000970\ttotal: 23.5s\tremaining: 17.3s\n",
            "576:\tlearn: 0.0000969\ttotal: 23.6s\tremaining: 17.3s\n",
            "577:\tlearn: 0.0000969\ttotal: 23.7s\tremaining: 17.3s\n",
            "578:\tlearn: 0.0000969\ttotal: 23.7s\tremaining: 17.2s\n",
            "579:\tlearn: 0.0000967\ttotal: 23.7s\tremaining: 17.2s\n",
            "580:\tlearn: 0.0000954\ttotal: 23.8s\tremaining: 17.2s\n",
            "581:\tlearn: 0.0000954\ttotal: 23.9s\tremaining: 17.1s\n",
            "582:\tlearn: 0.0000947\ttotal: 23.9s\tremaining: 17.1s\n",
            "583:\tlearn: 0.0000947\ttotal: 24s\tremaining: 17.1s\n",
            "584:\tlearn: 0.0000947\ttotal: 24s\tremaining: 17s\n",
            "585:\tlearn: 0.0000947\ttotal: 24.1s\tremaining: 17s\n",
            "586:\tlearn: 0.0000947\ttotal: 24.1s\tremaining: 17s\n",
            "587:\tlearn: 0.0000934\ttotal: 24.2s\tremaining: 16.9s\n",
            "588:\tlearn: 0.0000934\ttotal: 24.2s\tremaining: 16.9s\n",
            "589:\tlearn: 0.0000934\ttotal: 24.3s\tremaining: 16.9s\n",
            "590:\tlearn: 0.0000933\ttotal: 24.4s\tremaining: 16.9s\n",
            "591:\tlearn: 0.0000932\ttotal: 24.4s\tremaining: 16.8s\n",
            "592:\tlearn: 0.0000932\ttotal: 24.5s\tremaining: 16.8s\n",
            "593:\tlearn: 0.0000931\ttotal: 24.5s\tremaining: 16.8s\n",
            "594:\tlearn: 0.0000931\ttotal: 24.6s\tremaining: 16.7s\n",
            "595:\tlearn: 0.0000931\ttotal: 24.6s\tremaining: 16.7s\n",
            "596:\tlearn: 0.0000931\ttotal: 24.7s\tremaining: 16.7s\n",
            "597:\tlearn: 0.0000931\ttotal: 24.7s\tremaining: 16.6s\n",
            "598:\tlearn: 0.0000931\ttotal: 24.8s\tremaining: 16.6s\n",
            "599:\tlearn: 0.0000931\ttotal: 24.9s\tremaining: 16.6s\n",
            "600:\tlearn: 0.0000930\ttotal: 24.9s\tremaining: 16.6s\n",
            "601:\tlearn: 0.0000930\ttotal: 25s\tremaining: 16.5s\n",
            "602:\tlearn: 0.0000930\ttotal: 25s\tremaining: 16.5s\n",
            "603:\tlearn: 0.0000930\ttotal: 25.1s\tremaining: 16.4s\n",
            "604:\tlearn: 0.0000927\ttotal: 25.1s\tremaining: 16.4s\n",
            "605:\tlearn: 0.0000917\ttotal: 25.1s\tremaining: 16.3s\n",
            "606:\tlearn: 0.0000911\ttotal: 25.2s\tremaining: 16.3s\n",
            "607:\tlearn: 0.0000911\ttotal: 25.2s\tremaining: 16.3s\n",
            "608:\tlearn: 0.0000911\ttotal: 25.3s\tremaining: 16.2s\n",
            "609:\tlearn: 0.0000911\ttotal: 25.3s\tremaining: 16.2s\n",
            "610:\tlearn: 0.0000911\ttotal: 25.4s\tremaining: 16.2s\n",
            "611:\tlearn: 0.0000911\ttotal: 25.5s\tremaining: 16.2s\n",
            "612:\tlearn: 0.0000910\ttotal: 25.5s\tremaining: 16.1s\n",
            "613:\tlearn: 0.0000910\ttotal: 25.6s\tremaining: 16.1s\n",
            "614:\tlearn: 0.0000910\ttotal: 25.6s\tremaining: 16.1s\n",
            "615:\tlearn: 0.0000910\ttotal: 25.7s\tremaining: 16s\n",
            "616:\tlearn: 0.0000908\ttotal: 25.7s\tremaining: 16s\n",
            "617:\tlearn: 0.0000908\ttotal: 25.8s\tremaining: 15.9s\n",
            "618:\tlearn: 0.0000907\ttotal: 25.8s\tremaining: 15.9s\n",
            "619:\tlearn: 0.0000907\ttotal: 25.9s\tremaining: 15.8s\n",
            "620:\tlearn: 0.0000907\ttotal: 25.9s\tremaining: 15.8s\n",
            "621:\tlearn: 0.0000907\ttotal: 25.9s\tremaining: 15.8s\n",
            "622:\tlearn: 0.0000906\ttotal: 26s\tremaining: 15.7s\n",
            "623:\tlearn: 0.0000906\ttotal: 26s\tremaining: 15.7s\n",
            "624:\tlearn: 0.0000901\ttotal: 26.1s\tremaining: 15.6s\n",
            "625:\tlearn: 0.0000900\ttotal: 26.1s\tremaining: 15.6s\n",
            "626:\tlearn: 0.0000900\ttotal: 26.1s\tremaining: 15.5s\n",
            "627:\tlearn: 0.0000900\ttotal: 26.2s\tremaining: 15.5s\n",
            "628:\tlearn: 0.0000900\ttotal: 26.2s\tremaining: 15.5s\n",
            "629:\tlearn: 0.0000894\ttotal: 26.3s\tremaining: 15.5s\n",
            "630:\tlearn: 0.0000893\ttotal: 26.4s\tremaining: 15.4s\n",
            "631:\tlearn: 0.0000893\ttotal: 26.5s\tremaining: 15.4s\n",
            "632:\tlearn: 0.0000893\ttotal: 26.5s\tremaining: 15.4s\n",
            "633:\tlearn: 0.0000884\ttotal: 26.6s\tremaining: 15.3s\n",
            "634:\tlearn: 0.0000884\ttotal: 26.6s\tremaining: 15.3s\n",
            "635:\tlearn: 0.0000884\ttotal: 26.6s\tremaining: 15.2s\n",
            "636:\tlearn: 0.0000884\ttotal: 26.8s\tremaining: 15.3s\n",
            "637:\tlearn: 0.0000884\ttotal: 26.9s\tremaining: 15.3s\n",
            "638:\tlearn: 0.0000883\ttotal: 27s\tremaining: 15.2s\n",
            "639:\tlearn: 0.0000883\ttotal: 27.3s\tremaining: 15.3s\n",
            "640:\tlearn: 0.0000883\ttotal: 27.5s\tremaining: 15.4s\n",
            "641:\tlearn: 0.0000883\ttotal: 27.7s\tremaining: 15.5s\n",
            "642:\tlearn: 0.0000883\ttotal: 28s\tremaining: 15.5s\n",
            "643:\tlearn: 0.0000883\ttotal: 28.3s\tremaining: 15.6s\n",
            "644:\tlearn: 0.0000883\ttotal: 28.4s\tremaining: 15.6s\n",
            "645:\tlearn: 0.0000883\ttotal: 28.5s\tremaining: 15.6s\n",
            "646:\tlearn: 0.0000883\ttotal: 28.7s\tremaining: 15.6s\n",
            "647:\tlearn: 0.0000881\ttotal: 28.8s\tremaining: 15.6s\n",
            "648:\tlearn: 0.0000881\ttotal: 28.9s\tremaining: 15.6s\n",
            "649:\tlearn: 0.0000880\ttotal: 29.1s\tremaining: 15.7s\n",
            "650:\tlearn: 0.0000870\ttotal: 29.2s\tremaining: 15.7s\n",
            "651:\tlearn: 0.0000868\ttotal: 29.3s\tremaining: 15.7s\n",
            "652:\tlearn: 0.0000867\ttotal: 29.4s\tremaining: 15.6s\n",
            "653:\tlearn: 0.0000858\ttotal: 29.8s\tremaining: 15.7s\n",
            "654:\tlearn: 0.0000858\ttotal: 29.8s\tremaining: 15.7s\n",
            "655:\tlearn: 0.0000858\ttotal: 29.9s\tremaining: 15.7s\n",
            "656:\tlearn: 0.0000858\ttotal: 30.2s\tremaining: 15.7s\n",
            "657:\tlearn: 0.0000858\ttotal: 30.3s\tremaining: 15.8s\n",
            "658:\tlearn: 0.0000858\ttotal: 30.5s\tremaining: 15.8s\n",
            "659:\tlearn: 0.0000852\ttotal: 30.5s\tremaining: 15.7s\n",
            "660:\tlearn: 0.0000852\ttotal: 30.6s\tremaining: 15.7s\n",
            "661:\tlearn: 0.0000852\ttotal: 30.6s\tremaining: 15.6s\n",
            "662:\tlearn: 0.0000852\ttotal: 30.7s\tremaining: 15.6s\n",
            "663:\tlearn: 0.0000852\ttotal: 30.7s\tremaining: 15.6s\n",
            "664:\tlearn: 0.0000850\ttotal: 30.8s\tremaining: 15.5s\n",
            "665:\tlearn: 0.0000850\ttotal: 30.8s\tremaining: 15.5s\n",
            "666:\tlearn: 0.0000849\ttotal: 30.9s\tremaining: 15.4s\n",
            "667:\tlearn: 0.0000849\ttotal: 30.9s\tremaining: 15.4s\n",
            "668:\tlearn: 0.0000847\ttotal: 30.9s\tremaining: 15.3s\n",
            "669:\tlearn: 0.0000847\ttotal: 31s\tremaining: 15.3s\n",
            "670:\tlearn: 0.0000847\ttotal: 31s\tremaining: 15.2s\n",
            "671:\tlearn: 0.0000847\ttotal: 31s\tremaining: 15.2s\n",
            "672:\tlearn: 0.0000842\ttotal: 31.1s\tremaining: 15.1s\n",
            "673:\tlearn: 0.0000842\ttotal: 31.1s\tremaining: 15.1s\n",
            "674:\tlearn: 0.0000833\ttotal: 31.2s\tremaining: 15s\n",
            "675:\tlearn: 0.0000833\ttotal: 31.2s\tremaining: 15s\n",
            "676:\tlearn: 0.0000833\ttotal: 31.2s\tremaining: 14.9s\n",
            "677:\tlearn: 0.0000833\ttotal: 31.3s\tremaining: 14.9s\n",
            "678:\tlearn: 0.0000833\ttotal: 31.3s\tremaining: 14.8s\n",
            "679:\tlearn: 0.0000833\ttotal: 31.4s\tremaining: 14.8s\n",
            "680:\tlearn: 0.0000833\ttotal: 31.4s\tremaining: 14.7s\n",
            "681:\tlearn: 0.0000833\ttotal: 31.4s\tremaining: 14.7s\n",
            "682:\tlearn: 0.0000832\ttotal: 31.5s\tremaining: 14.6s\n",
            "683:\tlearn: 0.0000832\ttotal: 31.5s\tremaining: 14.5s\n",
            "684:\tlearn: 0.0000830\ttotal: 31.5s\tremaining: 14.5s\n",
            "685:\tlearn: 0.0000830\ttotal: 31.6s\tremaining: 14.4s\n",
            "686:\tlearn: 0.0000830\ttotal: 31.6s\tremaining: 14.4s\n",
            "687:\tlearn: 0.0000830\ttotal: 31.6s\tremaining: 14.4s\n",
            "688:\tlearn: 0.0000828\ttotal: 31.7s\tremaining: 14.3s\n",
            "689:\tlearn: 0.0000820\ttotal: 31.7s\tremaining: 14.3s\n",
            "690:\tlearn: 0.0000820\ttotal: 31.8s\tremaining: 14.2s\n",
            "691:\tlearn: 0.0000820\ttotal: 31.8s\tremaining: 14.2s\n",
            "692:\tlearn: 0.0000810\ttotal: 31.9s\tremaining: 14.1s\n",
            "693:\tlearn: 0.0000810\ttotal: 31.9s\tremaining: 14.1s\n",
            "694:\tlearn: 0.0000810\ttotal: 31.9s\tremaining: 14s\n",
            "695:\tlearn: 0.0000809\ttotal: 32s\tremaining: 14s\n",
            "696:\tlearn: 0.0000809\ttotal: 32s\tremaining: 13.9s\n",
            "697:\tlearn: 0.0000809\ttotal: 32s\tremaining: 13.9s\n",
            "698:\tlearn: 0.0000809\ttotal: 32.1s\tremaining: 13.8s\n",
            "699:\tlearn: 0.0000809\ttotal: 32.1s\tremaining: 13.8s\n",
            "700:\tlearn: 0.0000809\ttotal: 32.1s\tremaining: 13.7s\n",
            "701:\tlearn: 0.0000809\ttotal: 32.2s\tremaining: 13.7s\n",
            "702:\tlearn: 0.0000809\ttotal: 32.2s\tremaining: 13.6s\n",
            "703:\tlearn: 0.0000809\ttotal: 32.3s\tremaining: 13.6s\n",
            "704:\tlearn: 0.0000809\ttotal: 32.3s\tremaining: 13.5s\n",
            "705:\tlearn: 0.0000809\ttotal: 32.4s\tremaining: 13.5s\n",
            "706:\tlearn: 0.0000800\ttotal: 32.4s\tremaining: 13.4s\n",
            "707:\tlearn: 0.0000799\ttotal: 32.5s\tremaining: 13.4s\n",
            "708:\tlearn: 0.0000798\ttotal: 32.5s\tremaining: 13.3s\n",
            "709:\tlearn: 0.0000798\ttotal: 32.6s\tremaining: 13.3s\n",
            "710:\tlearn: 0.0000797\ttotal: 32.6s\tremaining: 13.3s\n",
            "711:\tlearn: 0.0000796\ttotal: 32.6s\tremaining: 13.2s\n",
            "712:\tlearn: 0.0000796\ttotal: 32.7s\tremaining: 13.2s\n",
            "713:\tlearn: 0.0000794\ttotal: 32.7s\tremaining: 13.1s\n",
            "714:\tlearn: 0.0000794\ttotal: 32.7s\tremaining: 13.1s\n",
            "715:\tlearn: 0.0000793\ttotal: 32.8s\tremaining: 13s\n",
            "716:\tlearn: 0.0000793\ttotal: 32.8s\tremaining: 13s\n",
            "717:\tlearn: 0.0000793\ttotal: 32.8s\tremaining: 12.9s\n",
            "718:\tlearn: 0.0000788\ttotal: 32.9s\tremaining: 12.9s\n",
            "719:\tlearn: 0.0000788\ttotal: 32.9s\tremaining: 12.8s\n",
            "720:\tlearn: 0.0000788\ttotal: 33s\tremaining: 12.8s\n",
            "721:\tlearn: 0.0000788\ttotal: 33s\tremaining: 12.7s\n",
            "722:\tlearn: 0.0000788\ttotal: 33s\tremaining: 12.7s\n",
            "723:\tlearn: 0.0000783\ttotal: 33.1s\tremaining: 12.6s\n",
            "724:\tlearn: 0.0000783\ttotal: 33.1s\tremaining: 12.6s\n",
            "725:\tlearn: 0.0000783\ttotal: 33.1s\tremaining: 12.5s\n",
            "726:\tlearn: 0.0000783\ttotal: 33.2s\tremaining: 12.5s\n",
            "727:\tlearn: 0.0000782\ttotal: 33.2s\tremaining: 12.4s\n",
            "728:\tlearn: 0.0000782\ttotal: 33.3s\tremaining: 12.4s\n",
            "729:\tlearn: 0.0000782\ttotal: 33.3s\tremaining: 12.3s\n",
            "730:\tlearn: 0.0000781\ttotal: 33.3s\tremaining: 12.3s\n",
            "731:\tlearn: 0.0000781\ttotal: 33.4s\tremaining: 12.2s\n",
            "732:\tlearn: 0.0000779\ttotal: 33.4s\tremaining: 12.2s\n",
            "733:\tlearn: 0.0000779\ttotal: 33.4s\tremaining: 12.1s\n",
            "734:\tlearn: 0.0000772\ttotal: 33.5s\tremaining: 12.1s\n",
            "735:\tlearn: 0.0000772\ttotal: 33.5s\tremaining: 12s\n",
            "736:\tlearn: 0.0000770\ttotal: 33.6s\tremaining: 12s\n",
            "737:\tlearn: 0.0000770\ttotal: 33.6s\tremaining: 11.9s\n",
            "738:\tlearn: 0.0000770\ttotal: 33.6s\tremaining: 11.9s\n",
            "739:\tlearn: 0.0000770\ttotal: 33.7s\tremaining: 11.8s\n",
            "740:\tlearn: 0.0000770\ttotal: 33.7s\tremaining: 11.8s\n",
            "741:\tlearn: 0.0000770\ttotal: 33.8s\tremaining: 11.7s\n",
            "742:\tlearn: 0.0000769\ttotal: 33.8s\tremaining: 11.7s\n",
            "743:\tlearn: 0.0000769\ttotal: 33.8s\tremaining: 11.6s\n",
            "744:\tlearn: 0.0000769\ttotal: 33.9s\tremaining: 11.6s\n",
            "745:\tlearn: 0.0000769\ttotal: 33.9s\tremaining: 11.5s\n",
            "746:\tlearn: 0.0000769\ttotal: 34s\tremaining: 11.5s\n",
            "747:\tlearn: 0.0000769\ttotal: 34s\tremaining: 11.5s\n",
            "748:\tlearn: 0.0000769\ttotal: 34.1s\tremaining: 11.4s\n",
            "749:\tlearn: 0.0000769\ttotal: 34.1s\tremaining: 11.4s\n",
            "750:\tlearn: 0.0000769\ttotal: 34.1s\tremaining: 11.3s\n",
            "751:\tlearn: 0.0000760\ttotal: 34.2s\tremaining: 11.3s\n",
            "752:\tlearn: 0.0000759\ttotal: 34.2s\tremaining: 11.2s\n",
            "753:\tlearn: 0.0000759\ttotal: 34.3s\tremaining: 11.2s\n",
            "754:\tlearn: 0.0000759\ttotal: 34.3s\tremaining: 11.1s\n",
            "755:\tlearn: 0.0000758\ttotal: 34.3s\tremaining: 11.1s\n",
            "756:\tlearn: 0.0000758\ttotal: 34.4s\tremaining: 11s\n",
            "757:\tlearn: 0.0000758\ttotal: 34.4s\tremaining: 11s\n",
            "758:\tlearn: 0.0000758\ttotal: 34.4s\tremaining: 10.9s\n",
            "759:\tlearn: 0.0000758\ttotal: 34.5s\tremaining: 10.9s\n",
            "760:\tlearn: 0.0000758\ttotal: 34.5s\tremaining: 10.8s\n",
            "761:\tlearn: 0.0000758\ttotal: 34.6s\tremaining: 10.8s\n",
            "762:\tlearn: 0.0000750\ttotal: 34.6s\tremaining: 10.7s\n",
            "763:\tlearn: 0.0000750\ttotal: 34.6s\tremaining: 10.7s\n",
            "764:\tlearn: 0.0000750\ttotal: 34.7s\tremaining: 10.6s\n",
            "765:\tlearn: 0.0000750\ttotal: 34.7s\tremaining: 10.6s\n",
            "766:\tlearn: 0.0000750\ttotal: 34.7s\tremaining: 10.6s\n",
            "767:\tlearn: 0.0000750\ttotal: 34.8s\tremaining: 10.5s\n",
            "768:\tlearn: 0.0000750\ttotal: 34.8s\tremaining: 10.5s\n",
            "769:\tlearn: 0.0000750\ttotal: 34.9s\tremaining: 10.4s\n",
            "770:\tlearn: 0.0000741\ttotal: 34.9s\tremaining: 10.4s\n",
            "771:\tlearn: 0.0000741\ttotal: 34.9s\tremaining: 10.3s\n",
            "772:\tlearn: 0.0000741\ttotal: 35s\tremaining: 10.3s\n",
            "773:\tlearn: 0.0000741\ttotal: 35s\tremaining: 10.2s\n",
            "774:\tlearn: 0.0000741\ttotal: 35.1s\tremaining: 10.2s\n",
            "775:\tlearn: 0.0000739\ttotal: 35.1s\tremaining: 10.1s\n",
            "776:\tlearn: 0.0000739\ttotal: 35.1s\tremaining: 10.1s\n",
            "777:\tlearn: 0.0000739\ttotal: 35.2s\tremaining: 10s\n",
            "778:\tlearn: 0.0000739\ttotal: 35.2s\tremaining: 9.99s\n",
            "779:\tlearn: 0.0000739\ttotal: 35.3s\tremaining: 9.94s\n",
            "780:\tlearn: 0.0000738\ttotal: 35.3s\tremaining: 9.9s\n",
            "781:\tlearn: 0.0000738\ttotal: 35.3s\tremaining: 9.85s\n",
            "782:\tlearn: 0.0000738\ttotal: 35.4s\tremaining: 9.8s\n",
            "783:\tlearn: 0.0000738\ttotal: 35.4s\tremaining: 9.76s\n",
            "784:\tlearn: 0.0000738\ttotal: 35.4s\tremaining: 9.71s\n",
            "785:\tlearn: 0.0000738\ttotal: 35.5s\tremaining: 9.66s\n",
            "786:\tlearn: 0.0000738\ttotal: 35.5s\tremaining: 9.61s\n",
            "787:\tlearn: 0.0000738\ttotal: 35.5s\tremaining: 9.56s\n",
            "788:\tlearn: 0.0000738\ttotal: 35.6s\tremaining: 9.52s\n",
            "789:\tlearn: 0.0000734\ttotal: 35.6s\tremaining: 9.46s\n",
            "790:\tlearn: 0.0000734\ttotal: 35.7s\tremaining: 9.42s\n",
            "791:\tlearn: 0.0000734\ttotal: 35.7s\tremaining: 9.37s\n",
            "792:\tlearn: 0.0000734\ttotal: 35.7s\tremaining: 9.32s\n",
            "793:\tlearn: 0.0000732\ttotal: 35.8s\tremaining: 9.28s\n",
            "794:\tlearn: 0.0000732\ttotal: 35.8s\tremaining: 9.23s\n",
            "795:\tlearn: 0.0000732\ttotal: 35.8s\tremaining: 9.18s\n",
            "796:\tlearn: 0.0000732\ttotal: 35.9s\tremaining: 9.13s\n",
            "797:\tlearn: 0.0000732\ttotal: 35.9s\tremaining: 9.09s\n",
            "798:\tlearn: 0.0000732\ttotal: 35.9s\tremaining: 9.04s\n",
            "799:\tlearn: 0.0000732\ttotal: 36s\tremaining: 8.99s\n",
            "800:\tlearn: 0.0000732\ttotal: 36s\tremaining: 8.94s\n",
            "801:\tlearn: 0.0000732\ttotal: 36s\tremaining: 8.9s\n",
            "802:\tlearn: 0.0000732\ttotal: 36.1s\tremaining: 8.85s\n",
            "803:\tlearn: 0.0000732\ttotal: 36.1s\tremaining: 8.8s\n",
            "804:\tlearn: 0.0000732\ttotal: 36.2s\tremaining: 8.76s\n",
            "805:\tlearn: 0.0000732\ttotal: 36.2s\tremaining: 8.71s\n",
            "806:\tlearn: 0.0000732\ttotal: 36.2s\tremaining: 8.66s\n",
            "807:\tlearn: 0.0000732\ttotal: 36.3s\tremaining: 8.62s\n",
            "808:\tlearn: 0.0000732\ttotal: 36.3s\tremaining: 8.57s\n",
            "809:\tlearn: 0.0000731\ttotal: 36.4s\tremaining: 8.53s\n",
            "810:\tlearn: 0.0000731\ttotal: 36.4s\tremaining: 8.48s\n",
            "811:\tlearn: 0.0000731\ttotal: 36.4s\tremaining: 8.44s\n",
            "812:\tlearn: 0.0000731\ttotal: 36.5s\tremaining: 8.39s\n",
            "813:\tlearn: 0.0000731\ttotal: 36.5s\tremaining: 8.34s\n",
            "814:\tlearn: 0.0000730\ttotal: 36.6s\tremaining: 8.3s\n",
            "815:\tlearn: 0.0000730\ttotal: 36.6s\tremaining: 8.25s\n",
            "816:\tlearn: 0.0000730\ttotal: 36.6s\tremaining: 8.2s\n",
            "817:\tlearn: 0.0000730\ttotal: 36.7s\tremaining: 8.16s\n",
            "818:\tlearn: 0.0000730\ttotal: 36.7s\tremaining: 8.12s\n",
            "819:\tlearn: 0.0000729\ttotal: 36.8s\tremaining: 8.07s\n",
            "820:\tlearn: 0.0000729\ttotal: 36.8s\tremaining: 8.03s\n",
            "821:\tlearn: 0.0000729\ttotal: 36.9s\tremaining: 7.98s\n",
            "822:\tlearn: 0.0000729\ttotal: 36.9s\tremaining: 7.93s\n",
            "823:\tlearn: 0.0000729\ttotal: 36.9s\tremaining: 7.89s\n",
            "824:\tlearn: 0.0000729\ttotal: 37s\tremaining: 7.84s\n",
            "825:\tlearn: 0.0000729\ttotal: 37s\tremaining: 7.8s\n",
            "826:\tlearn: 0.0000729\ttotal: 37s\tremaining: 7.75s\n",
            "827:\tlearn: 0.0000729\ttotal: 37.1s\tremaining: 7.7s\n",
            "828:\tlearn: 0.0000729\ttotal: 37.1s\tremaining: 7.65s\n",
            "829:\tlearn: 0.0000729\ttotal: 37.1s\tremaining: 7.61s\n",
            "830:\tlearn: 0.0000723\ttotal: 37.2s\tremaining: 7.56s\n",
            "831:\tlearn: 0.0000723\ttotal: 37.2s\tremaining: 7.51s\n",
            "832:\tlearn: 0.0000723\ttotal: 37.2s\tremaining: 7.47s\n",
            "833:\tlearn: 0.0000723\ttotal: 37.3s\tremaining: 7.42s\n",
            "834:\tlearn: 0.0000722\ttotal: 37.3s\tremaining: 7.37s\n",
            "835:\tlearn: 0.0000722\ttotal: 37.4s\tremaining: 7.33s\n",
            "836:\tlearn: 0.0000722\ttotal: 37.4s\tremaining: 7.28s\n",
            "837:\tlearn: 0.0000722\ttotal: 37.4s\tremaining: 7.23s\n",
            "838:\tlearn: 0.0000722\ttotal: 37.5s\tremaining: 7.19s\n",
            "839:\tlearn: 0.0000722\ttotal: 37.5s\tremaining: 7.14s\n",
            "840:\tlearn: 0.0000722\ttotal: 37.5s\tremaining: 7.09s\n",
            "841:\tlearn: 0.0000722\ttotal: 37.6s\tremaining: 7.05s\n",
            "842:\tlearn: 0.0000722\ttotal: 37.6s\tremaining: 7s\n",
            "843:\tlearn: 0.0000721\ttotal: 37.6s\tremaining: 6.95s\n",
            "844:\tlearn: 0.0000721\ttotal: 37.7s\tremaining: 6.91s\n",
            "845:\tlearn: 0.0000721\ttotal: 37.7s\tremaining: 6.86s\n",
            "846:\tlearn: 0.0000721\ttotal: 37.7s\tremaining: 6.81s\n",
            "847:\tlearn: 0.0000721\ttotal: 37.8s\tremaining: 6.77s\n",
            "848:\tlearn: 0.0000720\ttotal: 37.8s\tremaining: 6.72s\n",
            "849:\tlearn: 0.0000720\ttotal: 37.8s\tremaining: 6.67s\n",
            "850:\tlearn: 0.0000720\ttotal: 37.9s\tremaining: 6.63s\n",
            "851:\tlearn: 0.0000720\ttotal: 37.9s\tremaining: 6.59s\n",
            "852:\tlearn: 0.0000714\ttotal: 38s\tremaining: 6.54s\n",
            "853:\tlearn: 0.0000714\ttotal: 38s\tremaining: 6.49s\n",
            "854:\tlearn: 0.0000712\ttotal: 38s\tremaining: 6.45s\n",
            "855:\tlearn: 0.0000712\ttotal: 38.1s\tremaining: 6.4s\n",
            "856:\tlearn: 0.0000712\ttotal: 38.1s\tremaining: 6.36s\n",
            "857:\tlearn: 0.0000711\ttotal: 38.1s\tremaining: 6.31s\n",
            "858:\tlearn: 0.0000711\ttotal: 38.2s\tremaining: 6.26s\n",
            "859:\tlearn: 0.0000704\ttotal: 38.2s\tremaining: 6.22s\n",
            "860:\tlearn: 0.0000700\ttotal: 38.2s\tremaining: 6.17s\n",
            "861:\tlearn: 0.0000700\ttotal: 38.3s\tremaining: 6.13s\n",
            "862:\tlearn: 0.0000700\ttotal: 38.4s\tremaining: 6.09s\n",
            "863:\tlearn: 0.0000693\ttotal: 38.4s\tremaining: 6.04s\n",
            "864:\tlearn: 0.0000691\ttotal: 38.4s\tremaining: 6s\n",
            "865:\tlearn: 0.0000691\ttotal: 38.5s\tremaining: 5.95s\n",
            "866:\tlearn: 0.0000690\ttotal: 38.5s\tremaining: 5.9s\n",
            "867:\tlearn: 0.0000686\ttotal: 38.5s\tremaining: 5.86s\n",
            "868:\tlearn: 0.0000686\ttotal: 38.6s\tremaining: 5.81s\n",
            "869:\tlearn: 0.0000686\ttotal: 38.6s\tremaining: 5.77s\n",
            "870:\tlearn: 0.0000686\ttotal: 38.6s\tremaining: 5.72s\n",
            "871:\tlearn: 0.0000686\ttotal: 38.6s\tremaining: 5.67s\n",
            "872:\tlearn: 0.0000686\ttotal: 38.7s\tremaining: 5.63s\n",
            "873:\tlearn: 0.0000686\ttotal: 38.7s\tremaining: 5.58s\n",
            "874:\tlearn: 0.0000686\ttotal: 38.8s\tremaining: 5.54s\n",
            "875:\tlearn: 0.0000686\ttotal: 38.8s\tremaining: 5.49s\n",
            "876:\tlearn: 0.0000686\ttotal: 38.8s\tremaining: 5.44s\n",
            "877:\tlearn: 0.0000686\ttotal: 38.9s\tremaining: 5.4s\n",
            "878:\tlearn: 0.0000685\ttotal: 38.9s\tremaining: 5.35s\n",
            "879:\tlearn: 0.0000685\ttotal: 38.9s\tremaining: 5.31s\n",
            "880:\tlearn: 0.0000685\ttotal: 39s\tremaining: 5.26s\n",
            "881:\tlearn: 0.0000685\ttotal: 39s\tremaining: 5.22s\n",
            "882:\tlearn: 0.0000685\ttotal: 39.1s\tremaining: 5.17s\n",
            "883:\tlearn: 0.0000685\ttotal: 39.1s\tremaining: 5.13s\n",
            "884:\tlearn: 0.0000685\ttotal: 39.1s\tremaining: 5.08s\n",
            "885:\tlearn: 0.0000680\ttotal: 39.2s\tremaining: 5.04s\n",
            "886:\tlearn: 0.0000680\ttotal: 39.2s\tremaining: 4.99s\n",
            "887:\tlearn: 0.0000672\ttotal: 39.2s\tremaining: 4.95s\n",
            "888:\tlearn: 0.0000672\ttotal: 39.3s\tremaining: 4.9s\n",
            "889:\tlearn: 0.0000669\ttotal: 39.3s\tremaining: 4.86s\n",
            "890:\tlearn: 0.0000669\ttotal: 39.3s\tremaining: 4.81s\n",
            "891:\tlearn: 0.0000669\ttotal: 39.4s\tremaining: 4.77s\n",
            "892:\tlearn: 0.0000669\ttotal: 39.4s\tremaining: 4.72s\n",
            "893:\tlearn: 0.0000669\ttotal: 39.5s\tremaining: 4.68s\n",
            "894:\tlearn: 0.0000669\ttotal: 39.5s\tremaining: 4.63s\n",
            "895:\tlearn: 0.0000669\ttotal: 39.5s\tremaining: 4.59s\n",
            "896:\tlearn: 0.0000669\ttotal: 39.6s\tremaining: 4.54s\n",
            "897:\tlearn: 0.0000667\ttotal: 39.6s\tremaining: 4.5s\n",
            "898:\tlearn: 0.0000667\ttotal: 39.7s\tremaining: 4.46s\n",
            "899:\tlearn: 0.0000667\ttotal: 39.7s\tremaining: 4.41s\n",
            "900:\tlearn: 0.0000667\ttotal: 39.7s\tremaining: 4.37s\n",
            "901:\tlearn: 0.0000667\ttotal: 39.8s\tremaining: 4.32s\n",
            "902:\tlearn: 0.0000666\ttotal: 39.8s\tremaining: 4.28s\n",
            "903:\tlearn: 0.0000666\ttotal: 39.8s\tremaining: 4.23s\n",
            "904:\tlearn: 0.0000666\ttotal: 39.9s\tremaining: 4.18s\n",
            "905:\tlearn: 0.0000666\ttotal: 39.9s\tremaining: 4.14s\n",
            "906:\tlearn: 0.0000666\ttotal: 39.9s\tremaining: 4.1s\n",
            "907:\tlearn: 0.0000665\ttotal: 40s\tremaining: 4.05s\n",
            "908:\tlearn: 0.0000665\ttotal: 40s\tremaining: 4.01s\n",
            "909:\tlearn: 0.0000665\ttotal: 40.1s\tremaining: 3.96s\n",
            "910:\tlearn: 0.0000665\ttotal: 40.1s\tremaining: 3.92s\n",
            "911:\tlearn: 0.0000659\ttotal: 40.1s\tremaining: 3.87s\n",
            "912:\tlearn: 0.0000659\ttotal: 40.2s\tremaining: 3.83s\n",
            "913:\tlearn: 0.0000659\ttotal: 40.2s\tremaining: 3.78s\n",
            "914:\tlearn: 0.0000657\ttotal: 40.3s\tremaining: 3.74s\n",
            "915:\tlearn: 0.0000657\ttotal: 40.3s\tremaining: 3.69s\n",
            "916:\tlearn: 0.0000657\ttotal: 40.3s\tremaining: 3.65s\n",
            "917:\tlearn: 0.0000657\ttotal: 40.4s\tremaining: 3.61s\n",
            "918:\tlearn: 0.0000657\ttotal: 40.4s\tremaining: 3.56s\n",
            "919:\tlearn: 0.0000657\ttotal: 40.4s\tremaining: 3.52s\n",
            "920:\tlearn: 0.0000657\ttotal: 40.5s\tremaining: 3.47s\n",
            "921:\tlearn: 0.0000657\ttotal: 40.5s\tremaining: 3.43s\n",
            "922:\tlearn: 0.0000657\ttotal: 40.6s\tremaining: 3.38s\n",
            "923:\tlearn: 0.0000657\ttotal: 40.6s\tremaining: 3.34s\n",
            "924:\tlearn: 0.0000657\ttotal: 40.6s\tremaining: 3.29s\n",
            "925:\tlearn: 0.0000656\ttotal: 40.7s\tremaining: 3.25s\n",
            "926:\tlearn: 0.0000656\ttotal: 40.7s\tremaining: 3.21s\n",
            "927:\tlearn: 0.0000656\ttotal: 40.8s\tremaining: 3.16s\n",
            "928:\tlearn: 0.0000656\ttotal: 40.8s\tremaining: 3.12s\n",
            "929:\tlearn: 0.0000656\ttotal: 40.8s\tremaining: 3.07s\n",
            "930:\tlearn: 0.0000656\ttotal: 40.9s\tremaining: 3.03s\n",
            "931:\tlearn: 0.0000656\ttotal: 40.9s\tremaining: 2.99s\n",
            "932:\tlearn: 0.0000656\ttotal: 41s\tremaining: 2.94s\n",
            "933:\tlearn: 0.0000656\ttotal: 41s\tremaining: 2.9s\n",
            "934:\tlearn: 0.0000656\ttotal: 41.1s\tremaining: 2.85s\n",
            "935:\tlearn: 0.0000656\ttotal: 41.1s\tremaining: 2.81s\n",
            "936:\tlearn: 0.0000656\ttotal: 41.1s\tremaining: 2.77s\n",
            "937:\tlearn: 0.0000653\ttotal: 41.2s\tremaining: 2.72s\n",
            "938:\tlearn: 0.0000653\ttotal: 41.2s\tremaining: 2.68s\n",
            "939:\tlearn: 0.0000653\ttotal: 41.3s\tremaining: 2.63s\n",
            "940:\tlearn: 0.0000653\ttotal: 41.3s\tremaining: 2.59s\n",
            "941:\tlearn: 0.0000653\ttotal: 41.4s\tremaining: 2.55s\n",
            "942:\tlearn: 0.0000653\ttotal: 41.4s\tremaining: 2.5s\n",
            "943:\tlearn: 0.0000653\ttotal: 41.4s\tremaining: 2.46s\n",
            "944:\tlearn: 0.0000646\ttotal: 41.5s\tremaining: 2.41s\n",
            "945:\tlearn: 0.0000646\ttotal: 41.5s\tremaining: 2.37s\n",
            "946:\tlearn: 0.0000646\ttotal: 41.5s\tremaining: 2.33s\n",
            "947:\tlearn: 0.0000646\ttotal: 41.6s\tremaining: 2.28s\n",
            "948:\tlearn: 0.0000643\ttotal: 41.6s\tremaining: 2.24s\n",
            "949:\tlearn: 0.0000643\ttotal: 41.7s\tremaining: 2.19s\n",
            "950:\tlearn: 0.0000643\ttotal: 41.7s\tremaining: 2.15s\n",
            "951:\tlearn: 0.0000643\ttotal: 41.7s\tremaining: 2.1s\n",
            "952:\tlearn: 0.0000640\ttotal: 41.8s\tremaining: 2.06s\n",
            "953:\tlearn: 0.0000639\ttotal: 41.8s\tremaining: 2.02s\n",
            "954:\tlearn: 0.0000639\ttotal: 41.9s\tremaining: 1.97s\n",
            "955:\tlearn: 0.0000639\ttotal: 41.9s\tremaining: 1.93s\n",
            "956:\tlearn: 0.0000639\ttotal: 41.9s\tremaining: 1.88s\n",
            "957:\tlearn: 0.0000633\ttotal: 42s\tremaining: 1.84s\n",
            "958:\tlearn: 0.0000633\ttotal: 42s\tremaining: 1.79s\n",
            "959:\tlearn: 0.0000633\ttotal: 42s\tremaining: 1.75s\n",
            "960:\tlearn: 0.0000633\ttotal: 42.1s\tremaining: 1.71s\n",
            "961:\tlearn: 0.0000633\ttotal: 42.1s\tremaining: 1.66s\n",
            "962:\tlearn: 0.0000633\ttotal: 42.1s\tremaining: 1.62s\n",
            "963:\tlearn: 0.0000633\ttotal: 42.3s\tremaining: 1.58s\n",
            "964:\tlearn: 0.0000633\ttotal: 42.4s\tremaining: 1.54s\n",
            "965:\tlearn: 0.0000633\ttotal: 42.4s\tremaining: 1.49s\n",
            "966:\tlearn: 0.0000626\ttotal: 42.5s\tremaining: 1.45s\n",
            "967:\tlearn: 0.0000626\ttotal: 42.5s\tremaining: 1.4s\n",
            "968:\tlearn: 0.0000625\ttotal: 42.5s\tremaining: 1.36s\n",
            "969:\tlearn: 0.0000625\ttotal: 42.6s\tremaining: 1.32s\n",
            "970:\tlearn: 0.0000625\ttotal: 42.6s\tremaining: 1.27s\n",
            "971:\tlearn: 0.0000624\ttotal: 42.6s\tremaining: 1.23s\n",
            "972:\tlearn: 0.0000624\ttotal: 42.7s\tremaining: 1.18s\n",
            "973:\tlearn: 0.0000623\ttotal: 42.7s\tremaining: 1.14s\n",
            "974:\tlearn: 0.0000622\ttotal: 42.7s\tremaining: 1.1s\n",
            "975:\tlearn: 0.0000622\ttotal: 42.8s\tremaining: 1.05s\n",
            "976:\tlearn: 0.0000622\ttotal: 42.8s\tremaining: 1.01s\n",
            "977:\tlearn: 0.0000622\ttotal: 42.8s\tremaining: 964ms\n",
            "978:\tlearn: 0.0000622\ttotal: 42.9s\tremaining: 920ms\n",
            "979:\tlearn: 0.0000622\ttotal: 42.9s\tremaining: 876ms\n",
            "980:\tlearn: 0.0000622\ttotal: 42.9s\tremaining: 832ms\n",
            "981:\tlearn: 0.0000622\ttotal: 43s\tremaining: 788ms\n",
            "982:\tlearn: 0.0000622\ttotal: 43s\tremaining: 744ms\n",
            "983:\tlearn: 0.0000617\ttotal: 43.1s\tremaining: 700ms\n",
            "984:\tlearn: 0.0000617\ttotal: 43.1s\tremaining: 656ms\n",
            "985:\tlearn: 0.0000617\ttotal: 43.1s\tremaining: 613ms\n",
            "986:\tlearn: 0.0000617\ttotal: 43.2s\tremaining: 569ms\n",
            "987:\tlearn: 0.0000616\ttotal: 43.2s\tremaining: 525ms\n",
            "988:\tlearn: 0.0000616\ttotal: 43.2s\tremaining: 481ms\n",
            "989:\tlearn: 0.0000616\ttotal: 43.3s\tremaining: 437ms\n",
            "990:\tlearn: 0.0000616\ttotal: 43.3s\tremaining: 393ms\n",
            "991:\tlearn: 0.0000616\ttotal: 43.3s\tremaining: 349ms\n",
            "992:\tlearn: 0.0000616\ttotal: 43.4s\tremaining: 306ms\n",
            "993:\tlearn: 0.0000616\ttotal: 43.4s\tremaining: 262ms\n",
            "994:\tlearn: 0.0000616\ttotal: 43.4s\tremaining: 218ms\n",
            "995:\tlearn: 0.0000615\ttotal: 43.5s\tremaining: 175ms\n",
            "996:\tlearn: 0.0000615\ttotal: 43.5s\tremaining: 131ms\n",
            "997:\tlearn: 0.0000615\ttotal: 43.5s\tremaining: 87.3ms\n",
            "998:\tlearn: 0.0000615\ttotal: 43.6s\tremaining: 43.6ms\n",
            "999:\tlearn: 0.0000615\ttotal: 43.6s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x148319520>"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# <USE IT!>\n",
        "clf = CatBoostClassifier()\n",
        "clf.fit(sparse_data_train, clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOpZY9BGH7Q"
      },
      "source": [
        "**11. Пришлите в Контест balanced_accuracy_score на тестовой выборке, округлённый до двух знаков после запятой**. Стало ли сильно лучше от того, что мы воспользовались таким крутым классификатором?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 290,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bal_acc = balanced_accuracy_score(clean_data_test['average_bill'], clf.predict(sparse_data_test))\n",
        "bal_acc"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
