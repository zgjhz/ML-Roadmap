Here are some more important points on ANOVA. The F-test that we looked at assumes that all the groups have the same variance sigma squared. This needs to be checked. One way to roughly check it is simply look at the side-by-side boxplots, but there are also formal tests that can be used for that. Another assumption that we used was that the data are independent within and across groups. If the data we get are the results of a randomized controlled experiment, then this randomization condition would be met. On the other hand, if the data were obtained from an observational study, then we have to be careful with the analysis. Not only may the assumptions not be met, but we have to be careful with the conclusion, because remember, if we have an observational study, we cannot conclude that there is causation going on, because there could be confounders. Finally, suppose we do the ANOVA and the F-test rejects. So, the conclusion is that the group means are not all equal. The next question then is how are they different? One way to look more closely at those differences would be to use the two-sample t-tests, comparing all possible pairs of means. In this case, one would use the pooled standard deviation for the t-test. This is simply the within group variation. So, it's the square root of the error mean square, but since we would look at many of such comparisons, we have to be a little bit careful with our tests and have to make an adjustment. We will talk about this in the next module.