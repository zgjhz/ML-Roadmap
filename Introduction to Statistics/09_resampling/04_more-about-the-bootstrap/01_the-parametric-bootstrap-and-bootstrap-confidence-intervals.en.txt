Drawing a bootstrap sample by sampling with replacement from the data is called nonparametric bootstrap. Sometimes, we know more about the data. For example, we may know that the data follow a normal distribution, but we don't know the mean on the standard deviation. In that case, we may want to use that information. Of course, the obvious thing to do there is to simply estimate the unknown mean and standard deviation, and then simply sample from the normal distribution, with that mean and standard deviation. That's called parametric bootstrap. This type of sampling works if the data are independent, that is, X1 to Xn are really generated independently. But oftentimes, there's dependence in the data. For example, the data are observed over time. There are also bootstrap methods for dealing with that, but that's a somewhat specialized thing which we don't discuss here. Remember, the simple formula for an approximate confidence interval. We take theta hat and then we go a multiple z times the standard error in each direction. So, if we have a 1 - alpha for example, if alpha is 5%, we get a 95% confidence interval. Then we would look Z alpha half, so we would look at a normal curve and alpha half is 2.5%. So, we would look at z, 0.025, and we would simply plug this into the formula and get an approximate 95% confidence interval. We just saw how to estimate the standard error, in case there's no formula for it. But remember, the confidence interval is really based on the assumption that the sampling distribution of theta hat is roughly normal. That's the reason why we use the multiplier Z from the normal curve. What happens if theta hat is not approximately normal? Well, it turns out we can use the bootstrap in a more ambitious way. In fact, we can estimate the whole sampling distribution of theta hat, not just the standard error. The idea is that the sampling distribution of theta hat should be close to that of the bootstrap copies. And the sampling distribution to the bootstrap copies I can get simply by generating many bootstrap copies and making a histogram of those. This histogram may be quite far from normal. For example, it might look skewed like this. But I can simply find a 95% confidence interval by looking up 95% in the middle and looking at the appropriate cutoff points at each end. This is called the bootstrap percentile interval. You simply look up the right percentiles on each end so you have 1 - alpha in the middle. An alternative way to do that is not to bootstrap the distribution of theta hat, but to bootstrap the distribution of theta hat - theta. Why would one do that? The hope is that this is less sensitive to the particular value of theta, and therefore it may produce a more accurate confidence interval. The resulting confidence interval is called bootstrap pivotal interval, and the formula is given there.