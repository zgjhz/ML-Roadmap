The era of big data has led to a crisis of replicability and reproducibility, which has hit the mainstream news and which has even led some to question the scientific method. We will discuss some of the important causes of these problems and how to guard against them in doing statistical analysis. So, what is data snooping? Let's look at a famous Swedish study from 1992 which examined whether living near a power line causes adverse health effects. That study reported a statistically highly significant increase in childhood leukemia. But then curiously, when people followed up on that study, it turned out they couldn't really confirm that result. So why then did that study result in such a statistically significant outcome? To understand what's going on, we have to keep in mind that the study looked at 800 different health effects. That means the way to think about it is that the study did 800 different statistical tests. Remember that the p-value summarizes the evidence for an effect. And the interpretation is that the smaller the p-value, the stronger the evidence. In particular, if the p-value is smaller than 1%, than one says, that the test is highly significant. But keep in mind what that means. It means that if there's no effect, then there's still a 1% chance to get such a highly significant outcome. So, that means that if we do 800 tests, then even if there's nothing going on at all, we would expect to see about 800 times 1% which is roughly 8 highly significant outcomes just by chance. This is what happened in that Swedish study. They did so many tests that they found highly significant outcomes, even if there's nothing going on there. This effect has a name, it's called the multiple testing fallacy or the look-elsewhere effect. With the large amounts of data that are available nowadays, it's very easy to fall into this trap. The reason is that there are just so many potential relationships one can look into, that one sooner or later will run across a test which is significant just by chance. This behavior is called data snooping. One way people find out that data snooping was done is, if they cannot replicate the study. Replicating means to get the same conclusion with slightly different samples, procedures, and data analysis methods. Related to that is the problem of reproducibility. That means to get the same results then you simply use the same data and same methods that were claimed in the analysis. In past years, there have been some high profile publications that discuss the lack of replicability and reproducibility. Two interesting papers are, "How Science Goes Wrong", which is an article in The Economist, and the research paper, "Why Most Published Research Findings are False" by John Ioannidis.