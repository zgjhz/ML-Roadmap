Now, let's look at a slightly different situation where it turns out we can use a z-test. Last month, the President's approval rating in a sample of 1,000 likely voters was 55%. This month, a poll of 1,500 likely voters resulted in a rating of 58%. So the question is whether that's sufficient evidence to conclude that the rating has changed. In this case, we want to compare these two percentages. The first step is to find a way to write this down as a null hypothesis. So what we do is we write p1 for the proportion of all likely voters, which approved last month, and p2 for the proportion of voters approving this month. So, remember, the null hypothesis means that nothing unusual is going on. So that means p1 = p2. It's easier to look at the difference of these two numbers, and then the null hypothesis becomes that the difference is 0, and the alternative is that the difference is not equal to 0. Of course, each proportion is estimated by its corresponding percentage. So, now the key point is that the central limit theorem applies to the difference just as well as it does to the individual estimates. So that suggests that we can use a z-test. So, remember, for the z-test, we look at the difference of observed minus expected divided by the standard error. And then in this case, we will simply look at the observed difference and the expected difference and divide by the standard error of the difference. So we know what the observed difference is, that's just the difference of the percentages, and we can also figure out what the expected difference is because under the null hypothesis, these two are the same. So the difference is 0. And then, the question is, what's the standard error? That's really the only thing that's new here. It turns out that if the two proportions are independent, that means the two samples were taken independently, then the standard error of the difference is, we take the standard error of the first one, square it, take the standard error of the second one, square it, and take the square root of the sum. So let's plug this in. We get the difference of the percentages minus 0 on the top, and then we have the formula on the bottom. And now we simply use the formula for the standard error of a proportion, which is this thing there, and we have to square it. And now we have to simply estimate p1 by the percentage, we estimate p2 by the percentage, and what we get is 1.48. So, now we can find a p-value, by looking up a normal curve, we take 1.48. We look up the area to the right. It turns out that this is 7%, and the p-value is simply double of that, which is 14%. And of course, this is quite large, and so we cannot reject the null hypothesis. So we can use the formula for the standard error of a difference to also do a confidence interval. So this would simply be the observed difference of the percentages plus minus z times standard error. And then, we can simply plug in the formula, and what we get is -1% to 7%, in case z = 2, that is, if we have a 95% confidence. Again, this assumes that the two samples are drawn independently. So it turns out that if we do hypothesis testing and assume that the two proportions are equal, then we can actually improve the estimate of our standard error somewhat, and that's done by what's called pooling. The idea is that we should simply combine our two samples to estimate this proportion p1, which is the same as p2. And the fact that these two proportions are the same allows us to combine the samples. So let's do that. We have 55% of 1,000, which is 550 voters in the first sample. In the same way, we get 870 in the second sample who approve. So, in total, they have 1,420 approvals out of 2,500. And then, our pooled estimate is simply the fraction of those who approve out of the total sample size of the combined samples, and that's 56.8%. And then, we can compute the standard error of the difference using the formula we had before, but now what we do is we plug in this new number instead of the two different numbers, and what we get is 0.02022, which is almost the same as we got before. Now if we were to compare two means instead of two proportions, then the whole thing works really just in the same way. So, again, we get a formula for the standard error of the difference of two means, and that looks just like before. And remember, the standard error of an individual mean is the population standard deviation divided by the square root sample size. So, in this case, n1 is the sample size of the first sample. And of course, we would estimate Sigma 1 by s1, which is simply the sample standard deviation of the first sample. Now, remember, if the sample size is not large and we have to estimate Sigma, then we said we have to use a t-test instead of a z-test. And the same thing applies here. So if both sample sizes are not large, then we need to find the p-value using a t-distribution, and there's a complicated formula for that which you need to look up if you ever need it. If you look up the two-sample z-test in textbooks, then sometimes you see that there's some pooling going on if one can assume that the two standard deviations are the same. In that case, it is possible to estimate the common standard deviation using the pooled estimate whose formula is given here. However, it turns out that typically, there's not much advantage of doing that. Also, remember that this analysis rests on the assumption that the two standard deviations are the same, and there may be questions about that. And for these reasons, the pooled t-test is usually avoided. Again, remember that all of these two-sample tests we looked at require that the two samples are independent. It turns out you can also use a two-sample test in other special situations where the samples are actually dependent. For example, if one wants to compare the treatment effect when subjects are randomized into treatment and control groups. This is a special topic which you need to look up in case you ever come across it.