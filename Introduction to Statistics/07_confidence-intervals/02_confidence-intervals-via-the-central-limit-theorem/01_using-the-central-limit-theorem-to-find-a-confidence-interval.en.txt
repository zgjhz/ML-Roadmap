The idea of a confidence interval is that it gives a range of plausible values for a population parameter which we call mu. Usually, a confidence interval is constructed around an estimate for mu, which oftentimes is some form of an average. Let's look at some examples. In the first example, the population parameter mu we're interested in is the approval percentage among all 140 million likely voters. As an estimate, we use the approval percentage among the voters in our sample. This percentage is an average in our usual accounting schemes where we have 0 and 1 labels. As another example, suppose we want to measure the speed of light. In that case, our estimate would be the average of, say, 30 measurements. A key point now is that if we use averages, then we know that the central limit theorem applies. Therefore, we have a very simple form for the confidence interval, which is simply the estimate plus minus a z-value times the standard error. And that z-value simply comes from the normal approximation. Which z-value should we take? Well, that depends on the desired confidence level. For example, if we would like to have a 95% confidence level, then we get z = 1.96. That comes from normal approximation where we look at the value of the z such that 95% lies in the middle. That value of z is 1.96 or, oftentimes, we simply use 2. On the other hand, if we were interested in a 90% confidence level, then we would find z = 1.65. And for a 99% confidence level, we would get z = 2.58. The third number which we have to write down for our confidence interval is the SE. That's the standard error of the estimate. If the estimate is an average, for example, or a percentage, then we know that by the square root law, the standard error is sigma over square root sample size, where sigma is the standard deviation of the population. So, now we have a small problem because we need to know sigma, but we don't because sigma is the standard deviation of the population and we don't know what the population is. A way out of this is to simply estimate sigma from the sample. That is, we use a sample standard deviation in place of the population standard deviation. That's a very simple idea. And we will see later that this idea can be used in much more complicated situations. For that reason, it has a name. It's called the bootstrap principle.